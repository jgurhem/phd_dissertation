@TECHREPORT{rapport_Total_Petiton,
	AUTHOR =        {S. G. Petiton},
	TITLE =         {Expertise en calcul scientifique haute performance concernant la programmation par graphes de taches/composants et les nouveaux langages de programmation - Programmation par graphe de tâches-composants et migration de Kirchhoff},
	INSTITUTION =   {Laboratoire d'Informatique Fondamentale de Lille, Lille University},
	MONTH =         {6},
	YEAR  =         {2014},
	CONTACT =       {Serge.Petiton@univ-lille1.fr},
}

@ARTICLE{PingY1995,
	author={L. Ping and C. Yunhe},
	journal={Journal of Systems Engineering and Electronics},
	title={Seismic 3D prestack time migration on parallel computers},
	year={1995},
	volume={6},
	number={3},
	pages={49-55},
	keywords={Algorithm design and analysis;Computers;Data processing;Engines;Parallel processing;Partitioning algorithms;Three dimensional displays;3D prestack migration;parallel algorithm;parallel processing},
	month={9},
}

@INPROCEEDINGS{PTSCS2009,
	author={J. Panetta and T. Teixeira and P. R. P. de Souza Filho and C. A. da Cunha Finho and D. Sotelo and F. M. R. da Motta and S. S. Pinheiro and I. P. Junior and A. L. R. Rosa and L. R. Monnerat and L. T. Carneiro and C. H. B. de Albrecht},
	booktitle={2009 21st International Symposium on Computer Architecture and High Performance Computing},
	title={Accelerating Kirchhoff Migration by CPU and GPU Cooperation},
	year={2009},
	pages={26-32},
	keywords={computer graphics;coprocessors;geophysical signal processing;parallel processing;seismology;CPU cores;GPU idle cycles;GPU saturation;Kirchhoff prestack seismic migration acceleration;Petrobras production;control run;dynamic load balancing scheme;hot spot;total execution time;Acceleration;Computer architecture;Concurrent computing;Hardware;High performance computing;Life estimation;Load management;Parallel processing;Production;Testing;CPU-GPU Cooperation;Parallel Processing;Seismic Migration},
	doi={10.1109/SBAC-PAD.2009.29},
	ISSN={1550-6533},
	month={10},
}

@INPROCEEDINGS{XHCCC2014,
	author={R. Xu and M. Hugues and H. Calandra and S. Chandrasekaran and B. Chapman},
	booktitle={2014 First Workshop on Accelerator Programming using Directives},
	title={Accelerating Kirchhoff Migration on GPU Using Directives},
	year={2014},
	pages={37-46},
	keywords={extrapolation;geophysics computing;graphics processing units;interpolation;parallel architectures;program compilers;seismology;GPU architecture;GPU computation capability;Kirchhoff migration;OpenACC compiler;accelerator;computation algorithm;compute intensive portion;compute intensive property;directive-based programming model;extrapolation kernel function;high-level directive based programming model;interpolation kernel function;loop transformation technique;memory hierarchy;oil & gas industry;parallel architecture;productivity;programmability challenges;real-world production code;seismic migration application;Computational modeling;Computer architecture;Extrapolation;Graphics processing units;Interpolation;Kernel;Programming;OpenACC; Kirchhoff Migration; GPU; Directives; Programming Model},
	doi={10.1109/WACCPD.2014.8},
	month={11},
}

% First letter of the five first authors in upper case + year of the publication
% if less than five, use several more letters of the name of the first author in lower case
% example : Y. Zhao and M. Hategan and B. Clifford and I. Foster and G. von Laszewski in 2007
% ZHCFL2007, ZhHCF2007, ZhaHC2007, ZhaoH2007, Zhao2007a, Zhao2007b
@INPROCEEDINGS{BaTSA2012,
	author={M. Bauer and S. Treichler and E. Slaughter and A. Aiken},
	booktitle={High Performance Computing, Networking, Storage and Analysis (SC), 2012 International Conference for},
	title={Legion: Expressing locality and independence with logical regions},
	year={2012},
	volume={},
	number={},
	pages={1-11},
	keywords={distributed memory systems;parallel architectures;parallel machines;parallel programming;processor scheduling;Legion programs;deep complex memory hierarchies;distributed algorithm;heterogeneous processors;logical regions;memory hierarchy;parallel architectures;parallel scheduling algorithm;parallelism extraction;program data independence;program data locality;programmer controlled data movement;programming model;runtime system;task placement;Circuit simulation;Coherence;Out of order;Programming;Vegetation;Wires},
	doi={10.1109/SC.2012.71},
	ISSN={2167-4329},
	month={11},
}

@INPROCEEDINGS{ZHCFL2007,
	author={Y. Zhao and M. Hategan and B. Clifford and I. Foster and G. von Laszewski and V. Nefedova and I. Raicu and T. Stef-Praun and M. Wilde},
	booktitle={2007 IEEE Congress on Services (Services 2007)},
	title={Swift: Fast, Reliable, Loosely Coupled Parallel Computation},
	year={2007},
	volume={},
	number={},
	pages={199-206},
	abstract={We present Swift, a system that combines a novel scripting language called SwiftScript with a powerful runtime system based on CoG Karajan, Falkon, and Globus to allow for the concise specification, and reliable and efficient execution, of large loosely coupled computations. Swift adopts and adapts ideas first explored in the GriPhyN virtual data system, improving on that system in many regards. We describe the SwiftScript language and its use of XDTM to describe the logical structure of complex file system structures. We also present the Swift runtime system and its use of CoG Karajan, Falkon, and Globus services to dispatch and manage the execution of many tasks in parallel and grid environments. We describe application experiences and performance experiments that quantify the cost of Swift operations.},
	keywords={formal specification;grid computing;software reliability;GriPhyN virtual data system;Swift system;SwiftScript language;complex file system structures;runtime system;scripting language;Computer science;Concurrent computing;Data systems;Distributed computing;File systems;High performance computing;Laboratories;Magnetic analysis;Mathematics;Power system reliability},
	doi={10.1109/SERVICES.2007.63},
	ISSN={},
	month={7},
}

@INPROCEEDINGS{WAWKL2013,
	author={J. M. Wozniak and T. G. Armstrong and M. Wilde and D. S. Katz and E. Lusk and I. T. Foster},
	booktitle={2013 13th IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing},
	title={Swift/T: Large-Scale Application Composition via Distributed-Memory Dataflow Processing},
	year={2013},
	volume={},
	number={},
	pages={95-102},
	abstract={Many scientific applications are conceptually built up from independent component tasks as a parameter study, optimization, or other search. Large batches of these tasks may be executed on high-end computing systems, however, the coordination of the independent processes, their data, and their data dependencies is a significant scalability challenge. Many problems must be addressed, including load balancing, data distribution, notifications, concurrent programming, and linking to existing codes. In this work, we present Swift/T, a programming language and runtime that enables the rapid development of highly concurrent, task-parallel applications. Swift/Tis composed of several enabling technologies to address scalability challenges, offers a high-level optimizing compiler for user programming and debugging, and provides tools for binding user code in C/C++/Fortran into a logical script. In this work, we describe the Swift/T solution and present scaling results from the IBM Blue Gene/Pand Blue Gene/Q.},
	keywords={C++ language;FORTRAN;distributed memory systems;natural sciences computing;optimising compilers;parallel processing;program debugging;Blue Gene-Q;C-C++-Fortran;IBM Blue Gene-P;Swift-T solution;data dependency;distributed-memory dataflow processing;high-end computing systems;high-level optimizing compiler;large-scale application composition;programming language;scientific applications;task-parallel applications;user debugging;user programming;Computational modeling;Concurrent computing;Distributed databases;Libraries;Programming;Runtime;Turbines;ADLB;MPI;Swift;Swift/T;Turbine;dataflow},
	doi={10.1109/CCGrid.2013.99},
	ISSN={},
	month={5},
}

@inproceedings{WAMLK2012,
	author = {Wozniak, Justin M. and Armstrong, Timothy G. and Maheshwari, Ketan and Lusk, Ewing L. and Katz, Daniel S. and Wilde, Michael and Foster, Ian T.},
	title = {Turbine: A Distributed-memory Dataflow Engine for Extreme-scale Many-task Applications},
	booktitle = {Proceedings of the 1st ACM SIGMOD Workshop on Scalable Workflow Execution Engines and Technologies},
	series = {SWEET '12},
	year = {2012},
	isbn = {978-1-4503-1876-1},
	location = {Scottsdale, Arizona, USA},
	pages = {5:1--5:12},
	articleno = {5},
	numpages = {12},
	doi = {10.1145/2443416.2443421},
	acmid = {2443421},
	publisher = {ACM},
	keywords = {ADLB, MPI, concurrency, dataflow, exascale, swift, turbine},
}

@INPROCEEDINGS{PSVAW2014,
	author={J. C. Phillips and J. E. Stone and K. L. Vandivort and T. G. Armstrong and J. M. Wozniak and M. Wilde and K. Schulten},
	booktitle={2014 First Workshop for High Performance Technical Computing in Dynamic Languages},
	title={Petascale Tcl with NAMD, VMD, and Swift/T},
	year={2014},
	volume={},
	number={},
	pages={6-17},
	keywords={authoring languages;data flow computing;data visualisation;embedded systems;rendering (computer graphics);Blue Waters;NAMD;Petascale Tcl;Swift/T;VMD;analysis program;biomolecular visualization;embeddable dynamic language;high-performance parallel scripting language;movie rendering;parallel trajectory analysis;Biological system modeling;Computational modeling;Computers;Graphics processing units;Mathematical model;Programming;Trajectory},
	doi={10.1109/HPTCDL.2014.7},
	ISSN={},
	month={Nov},
}

@article{WHWCK2011,
	title = "Swift: A language for distributed parallel scripting",
	journal = "Parallel Computing",
	volume = "37",
	number = "9",
	pages = "633 - 652",
	year = "2011",
	note = "Emerging Programming Paradigms for Large-Scale Scientific Computing",
	issn = "0167-8191",
	doi = "10.1016/j.parco.2011.05.005",
	url = "http://www.sciencedirect.com/science/article/pii/S0167819111000524",
	author = "Michael Wilde and Mihael Hategan and Justin M. Wozniak and Ben Clifford and Daniel S. Katz and Ian Foster",
	keywords = "Swift, Parallel programming, Scripting, Dataflow"
}

@article{LusPB2010,
	title = {More scalability, less pain : A simple programming model and its implementation for extreme computing.},
	author = {Lusk, E. L. and Pieper, S. C. and Butler, R. M. and Middle Tennessee State Univ.},
	abstractNote = {This is the story of a simple programming model, its implementation for extreme computing, and a breakthrough in nuclear physics. A critical issue for the future of high-performance computing is the programming model to use on next-generation architectures. Described here is a promising approach: program very large machines by combining a simplified programming model with a scalable library implementation. The presentation takes the form of a case study in nuclear physics. The chosen application addresses fundamental issues in the origins of our Universe, while the library developed to enable this application on the largest computers may have applications beyond this one.},
	doi = {},
	journal = {SciDAC Rev.},
	number = 2010,
	volume = 17,
	place = {United States},
	year = {2010},
	month = {1}
}

@article{APWXF2011,
	author = {Adhikari, Aashish N. and Peng, Jian and Wilde, Michael and Xu, Jinbo and Freed, Karl F. and Sosnick, Tobin R.},
	title = {Modeling large regions in proteins: Applications to loops, termini, and folding},
	journal = {Protein Science},
	volume = {21},
	number = {1},
	pages = {107-121},
	keywords = {long loops, insertions, loop modeling, local protein structure prediction, molecular replacement},
	doi = {10.1002/pro.767},
	abstract = {Abstract Template‐based methods for predicting protein structure provide models for a significant portion of the protein but often contain insertions or chain ends (InsEnds) of indeterminate conformation. The local structure prediction “problem” entails modeling the InsEnds onto the rest of the protein. A well‐known limit involves predicting loops of ≤12 residues in crystal structures. However, InsEnds may contain as many as ∼50 amino acids, and the template‐based model of the protein itself may be imperfect. To address these challenges, we present a free modeling method for predicting the local structure of loops and large InsEnds in both crystal structures and template‐based models. The approach uses single amino acid torsional angle “pivot” moves of the protein backbone with a Cβ level representation. Nevertheless, our accuracy for loops is comparable to existing methods. We also apply a more stringent test, the blind structure prediction and refinement categories of the CASP9 tournament, where we improve the quality of several homology based models by modeling InsEnds as long as 45 amino acids, sizes generally inaccessible to existing loop prediction methods. Our approach ranks as one of the best in the CASP9 refinement category that involves improving template‐based models so that they can function as molecular replacement models to solve the phase problem for crystallographic structure determination.}
}

@inproceedings{WoiDS2011,
	author = {Woitaszek, Matthew and Dennis, John M. and Sines, Taleena R.},
	title = {Parallel High-resolution Climate Data Analysis Using Swift},
	booktitle = {Proceedings of the 2011 ACM International Workshop on Many Task Computing on Grids and Supercomputers},
	series = {MTAGS '11},
	year = {2011},
	isbn = {978-1-4503-1145-8},
	location = {Seattle, Washington, USA},
	pages = {5--14},
	numpages = {10},
	doi = {10.1145/2132876.2132882},
	acmid = {2132882},
	publisher = {ACM},
	keywords = {climate modeling, data-intensive computing, many-task computing, workflow orchestration},
}

@TECHREPORT{Beaud2013,
	AUTHOR =        {Laurence BEAUDE},
	TITLE =         {Reverse Time Migration using MPI and Coarray Fortran},
	INSTITUTION =   {RIKEN AICS},
	MONTH =         {5},
	YEAR  =         {2013},
}

@article{WuLL1996,
	author = {Wu, Wen‐Jing and Lines, Larry and Lu, Han‐Xing},
	year = {1996},
	month = {05},
	pages = {845-856},
	title = {Analysis of higher‐order, finite‐difference schemes in 3-D reverse‐time migration},
	volume = {61},
	booktitle = {GEOPHYSICS}
}

@INPROCEEDINGS{DelaP2004,
	author={O. Delannoy and S. Petiton},
	booktitle={Third International Symposium on Parallel and Distributed Computing/Third International Workshop on Algorithms, Models and Tools for Parallel Computing on Heterogeneous Networks},
	title={A peer to peer computing framework: design and performance evaluation of YML},
	year={2004},
	volume={},
	number={},
	pages={362-369},
	doi={10.1109/ISPDC.2004.7},
	ISSN={},
	month={7}
}

@INPROCEEDINGS{TsSHP2013,
	author={M. Tsuji and M. Sato and M. Hugues and S. Petiton},
	booktitle={2013 42nd International Conference on Parallel Processing},
	title={Multiple-SPMD Programming Environment Based on PGAS and Workflow toward Post-petascale Computing},
	year={2013},
	volume={},
	number={},
	pages={480-485},
	doi={10.1109/ICPP.2013.58},
	ISSN={0190-3918},
	month={10}
}

@INPROCEEDINGS{XMP,
	author={J. Lee and M. Sato},
	booktitle={2010 39th International Conference on Parallel Processing Workshops},
	title={Implementation and Performance Evaluation of XcalableMP: A Parallel Programming Language for Distributed Memory Systems},
	year={2010},
	pages={413-420},
	keywords={C language;FORTRAN;application program interfaces;distributed memory systems;message passing;parallel programming;program compilers;C language;CAF-like expressions;Fortran;MPI program writing;OpenMP-like directives;XcalableMP;distributed memory systems;internode communication;local view model;parallel programming language;performance evaluation;program compiler;sequential code;Arrays;Benchmark testing;Data models;Parallel processing;Parallel programming;Synchronization;High Performance Computing;Parallel Programming Language},
	doi={10.1109/ICPPW.2010.62},
	ISSN={0190-3918},
	month={09}
}

@INPROCEEDINGS{GuTPS2019,
 author = {Gurhem, J{\'e}r\^{o}me and Tsuji, Miwako and Petiton, Serge G. and Sato, Mitsuhisa},
 title = {Distributed and Parallel Programming Paradigms on the K Computer and a Cluster},
 booktitle = {Proceedings of the International Conference on High Performance Computing in Asia-Pacific Region},
 series = {HPC Asia 2019},
 year = {2019},
 isbn = {978-1-4503-6632-8},
 location = {Guangzhou, China},
 pages = {9--17},
 numpages = {9},
 url = {http://doi.acm.org/10.1145/3293320.3293330},
 doi = {10.1145/3293320.3293330},
 acmid = {3293330},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Graph of task components, Parallel and distributed programming paradigms, Resolution of linear system},
}

@incollection{ThaTL2002,
	author = "Douglas Thain and Todd Tannenbaum and Miron Livny",
	title = "{C}ondor and the Grid",
	editor = "Fran Berman and Geoffrey Fox and Tony Hey",
	booktitle = "Grid Computing: Making the Global Infrastructure a Reality",
	publisher = "John Wiley \& Sons Inc.",
	month = "12",
	year = "2002"
}

@article{DABLM2011,
	author = {Duran, Alejandro and Ayguadé, Eduard and Badia, Rosa M. and Labarta, Jesús and Martinell, Luis and Martorell, Xavier and Planas, Judit},
	title = {OmpSs: A proposal for programming heterogeneous multi-core architectures},
	journal = {Parallel Processing Letters},
	volume = {21},
	number = {02},
	pages = {173-193},
	year = {2011},
	doi = {10.1142/S0129626411000151},
}

@ARTICLE{BBDFH2013,
	author={G. Bosilca and A. Bouteiller and A. Danalis and M. Faverge and T. Herault and J. J. Dongarra},
	journal={Computing in Science Engineering},
	title={PaRSEC: Exploiting Heterogeneity to Enhance Scalability},
	year={2013},
	volume={15},
	number={6},
	pages={36-45},
	keywords={parallel processing;resource allocation;PaRSEC;application parallelism;core counts;high-performance computing system;memory access times;processor count;resource utilization;scalability enhancement;task parallelism;Adaptation models;Biological system modeling;Computational modeling;Computer architecture;Parallel processing;Programming;Runtime;Scalability;Adaptation models;Biological system modeling;Computational modeling;Computer architecture;HPC;Parallel processing;Programming;Runtime;Scalability;distributed programming;high-performance computing;programming paradigms;scheduling and task partitioning;scientific computing},
	doi={10.1109/MCSE.2013.98},
	ISSN={1521-9615},
	month={11},
}

@article{BBCKL2010,
	author = {Budimli\'{c}, Zoran and Burke, Michael and Cav{\'e}, Vincent and Knobe, Kathleen and Lowney, Geoff and Newton, Ryan and Palsberg, Jens and Peixotto, David and Sarkar, Vivek and Schlimbach, Frank and Ta\c{s}irlar, Sa\u{g}nak},
	title = {Concurrent Collections},
	journal = {Sci. Program.},
	issue_date = {August 2010},
	volume = {18},
	number = {3-4},
	month = {8},
	year = {2010},
	issn = {1058-9244},
	pages = {203--217},
	numpages = {15},
	url = {http://dx.doi.org/10.1155/2010/521797},
	doi = {10.1155/2010/521797},
	acmid = {1938486},
	publisher = {IOS Press},
	address = {Amsterdam, The Netherlands, The Netherlands},
	keywords = {Concurrent Collections (CnC), parallel programming, programming model},
}

@INPROCEEDINGS{ChaKV2010,
	author={A. Chandramowlishwaran and K. Knobe and R. Vuduc},
	booktitle={2010 IEEE International Symposium on Parallel Distributed Processing (IPDPS)},
	title={Performance evaluation of concurrent collections on high-performance multicore computing systems},
	year={2010},
	volume={},
	number={},
	pages={1-12},
	keywords={eigenvalues and eigenfunctions;matrix decomposition;multiprocessing systems;multi-threading;parallel algorithms;parallel programming;software performance evaluation;high performance multicore computing systems;parallel programming;concurrent collection performance evaluation;semantic scheduling constraints;asynchronous parallel algorithms;linear algebra algorithms;asynchronous parallel Cholesky factorization algorithms;partly asynchronous generalized eigensolver;dense symmetric matrices;sequential BIAS;multithreaded vendor tuned codes;ScaLAPACK;shared memory MPI;OpenMP;Cilk++;PLASMA 2.0;Intel Harpertown;Nehalem;AMD Barcelona system;Multicore processing;Concurrent computing;High performance computing;Parallel programming;Programming profession;Processor scheduling;Linear algebra;Symmetric matrices;Plasma density;Runtime},
	doi={10.1109/IPDPS.2010.5470404},
	ISSN={1530-2075},
	month={4},
}

@inbook{DoDSV1998c5,
	title = {Building Blocks in Linear Algebra},
	booktitle = {Numerical Linear Algebra for High-Performance Computers},
	chapter = {5},
	Year = {1998},
	author={Jack J. Dongarra and Iain S. Duff and Danny C. Sorensen and Henk A. van der Vorst},
	pages = {71-105},
	doi = {10.1137/1.9780898719611.ch5}
}


@INPROCEEDINGS{Petit1989,
    title={Parallelization on an MIMD computer with realtime Scheduler, Gauss-Jordan example},
    publisher = {North Holland},
    booktitle={Aspects of computation on asynchronous parallel processors},
    author={Serge G. Petiton},
    year={1989}
}

@article{Reckt2004,
	author = {Recktenwald, Gerald},
	year = {2004},
	month = {01},
	pages = {},
	title = {Finite-Difference Approximations to the Heat Equation},
	volume = {10},
	journal = {Mechanical Engineering}
}

@article{ACCCD2009,
  title={Exascale software study: Software challenges in extreme scale systems},
  author={Amarasinghe, Saman and Campbell, Dan and Carlson, William and Chien, Andrew and Dally, William and Elnohazy, Elmootazbellah and Hall, Mary and Harrison, Robert and Harrod, William and Hill, Kerry and others},
  journal={DARPA IPTO, Air Force Research Labs, Tech. Rep},
  pages={1--153},
  year={2009},
  publisher={Citeseer}
}


@ARTICLE{Borka2013,
author={S. {Borkar}},
journal={Journal of Lightwave Technology},
title={Role of Interconnects in the Future of Computing},
year={2013},
volume={31},
number={24},
pages={3927-3933},
keywords={optical interconnections;transistors;interconnects;computing;transistor integration capacity;ubiquitous;energy consumption;holistic hardware/software;Energy efficiency;Memory management;Optical interconnections;Materials;Bandwidth;Random access memory;Integrated circuit interconnections;Bandwidth;circuits and systems;communications technology;energy;latency;power;VLSI},
doi={10.1109/JLT.2013.2283277},
ISSN={0733-8724},
month={Dec},}


@article{BorkC2011,
 author = {Borkar, Shekhar and Chien, Andrew A.},
 title = {The Future of Microprocessors},
 journal = {Commun. ACM},
 issue_date = {May 2011},
 volume = {54},
 number = {5},
 month = may,
 year = {2011},
 issn = {0001-0782},
 pages = {67--77},
 numpages = {11},
 url = {http://doi.acm.org/10.1145/1941487.1941507},
 doi = {10.1145/1941487.1941507},
 acmid = {1941507},
 publisher = {ACM},
 address = {New York, NY, USA},
}

@article{NumrR1998,
 author = {Numrich, Robert W. and Reid, John},
 title = {Co-array Fortran for Parallel Programming},
 journal = {SIGPLAN Fortran Forum},
 issue_date = {Aug. 1998},
 volume = {17},
 number = {2},
 month = aug,
 year = {1998},
 issn = {1061-7264},
 pages = {1--31},
 numpages = {31},
 url = {http://doi.acm.org/10.1145/289918.289920},
 doi = {10.1145/289918.289920},
 acmid = {289920},
 publisher = {ACM},
 address = {New York, NY, USA},
}

@inproceedings{MeASJ2009,
 author = {Mellor-Crummey, John and Adhianto, Laksono and Scherer,III, William N. and Jin, Guohua},
 title = {A New Vision for Coarray Fortran},
 booktitle = {Proceedings of the Third Conference on Partitioned Global Address Space Programing Models},
 series = {PGAS '09},
 year = {2009},
 isbn = {978-1-60558-836-0},
 location = {Ashburn, Virginia, USA},
 pages = {5:1--5:9},
 articleno = {5},
 numpages = {9},
 url = {http://doi.acm.org/10.1145/1809961.1809969},
 doi = {10.1145/1809961.1809969},
 acmid = {1809969},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Coarray Fortran, parallel programming},
}

@InProceedings{LTOBS2012,
author="Lee, Jinpil
and Tran, Minh Tuan
and Odajima, Tetsuya
and Boku, Taisuke
and Sato, Mitsuhisa",
editor="Alexander, Michael
and D'Ambra, Pasqua
and Belloum, Adam
and Bosilca, George
and Cannataro, Mario
and Danelutto, Marco
and Di Martino, Beniamino
and Gerndt, Michael
and Jeannot, Emmanuel
and Namyst, Raymond
and Roman, Jean
and Scott, Stephen L.
and Traff, Jesper Larsson
and Vall{\'e}e, Geoffroy
and Weidendorfer, Josef",
title="An Extension of XcalableMP PGAS Lanaguage for Multi-node GPU Clusters",
booktitle="Euro-Par 2011: Parallel Processing Workshops",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="429--439",
abstract="A GPU is a promising device for further increasing computing performance in high performance computing field. Currently, many programming langauges are proposed for the GPU offloaded from the host, as well as CUDA. However, parallel programming with a multi-node GPU cluster, where each node has one or more GPUs, is a hard work. Users have to describe multi-level parallelism, both between nodes and within the GPU using MPI and a GPGPU language like CUDA. In this paper, we will propose a parallel programming language targeting multi-node GPU clusters. We extend XcalableMP, a parallel PGAS (Partitioned Global Address Space) programming language for PC clusters, to provide a productive parallel programming model for multi-node GPU clusters. Our performance evaluation with the N-body problem demonstrated that not only does our model achieve scalable performance, but it also increases productivity since it only requires small modifications to the serial code.",
isbn="978-3-642-29737-3"
}


@INPROCEEDINGS{NMSTH2014,
author={M. {Nakao} and H. {Murai} and T. {Shimosaka} and A. {Tabuchi} and T. {Hanawa} and Y. {Kodama} and T. {Boku} and M. {Sato}},
booktitle={2014 First Workshop on Accelerator Programming using Directives},
title={XcalableACC: Extension of XcalableMP PGAS Language Using OpenACC for Accelerator Clusters},
year={2014},
volume={},
number={},
pages={27-36},
keywords={distributed memory systems;message passing;parallel programming;source code (software);XcalableACC;XcalableMP PGAS language;OpenACC;accelerator clusters;XACC programming model;XMP Partitioned Global Address Space language;XMP PGAS language;stencil applications;Omni XACC compiler;halo region;accelerator memory;tightly coupled accelerators;TCA;HIMENO benchmark;source code;message passing interface;MPI programming model;GPUDirect RDMA;InfiniBand;Arrays;Programming;Indexes;Syntactics;Graphics processing units;Synchronization;Computational modeling;Design language; Development Compiler; Accelerator Cluster; Partitioned Global Address Space Language},
doi={10.1109/WACCPD.2014.6},
ISSN={},
month={Nov},}

@article{HuMPC2011,
	title = "ASIODS - An Asynchronous and Smart I/O Delegation System",
	journal = "Procedia Computer Science",
	volume = "4",
	pages = "471 - 478",
	year = "2011",
	note = "Proceedings of the International Conference on Computational Science, ICCS 2011",
	issn = "1877-0509",
	doi = "https://doi.org/10.1016/j.procs.2011.04.049",
	url = "http://www.sciencedirect.com/science/article/pii/S1877050911001074",
	author = "Maxime R. Hugues and Michael Moretti and Serge G. Petiton and Henri Calandra",
	keywords = "I/O Delegation, Graph Description, Distributed System"
}

@inproceedings{SaHTS2001,
  title={OmniRPC: A Grid RPC facility for cluster and global computing in OpenMP},
  author={Sato, Mitsuhisa and Hirano, Motonari and Tanaka, Yoshio and Sekiguchi, Satoshi},
  booktitle={International Workshop on OpenMP Applications and Tools},
  pages={130-136},
  year={2001},
  organization={Springer},
  doi = {10.1007/3-540-44587-0_12}
}


@INPROCEEDINGS{SatBT2003,
author={M. {Sato} and T. {Boku} and D. {Takahashi}},
booktitle={CCGrid 2003. 3rd IEEE/ACM International Symposium on Cluster Computing and the Grid, 2003. Proceedings.},
title={OmniRPC: a grid RPC system for parallel programming in cluster and grid environment},
year={2003},
volume={},
number={},
pages={206-213},
keywords={grid computing;remote procedure calls;workstation clusters;parallel programming;application program interfaces;client-server systems;open systems;OmniRPC grid RPC system;parallel programming;grid environment;cluster environment;API;remote procedure calls;OpenMP application program interfaces;automatic-initializable remote module;Globus environment;remote computing hosts;Parallel programming;Computer networks;Grid computing;Libraries;Yarn;High performance computing;Distributed computing;Pervasive computing;Program processors;Programming profession},
doi={10.1109/CCGRID.2003.1199370},
ISSN={},
month={May},}

@inproceedings{TsuPS2015,
 author = {Tsuji, Miwako and Petiton, Serge and Sato, Mitsuhisa},
 title = {Fault Tolerance Features of a New multi-SPMD Programming/Execution Environment},
 booktitle = {Proceedings of the First International Workshop on Extreme Scale Programming Models and Middleware},
 series = {ESPM '15},
 year = {2015},
 isbn = {978-1-4503-3996-4},
 location = {Austin, Texas},
 pages = {20--27},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/2832241.2832243},
 doi = {10.1145/2832241.2832243},
 acmid = {2832243},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {PGAS, fault-tolerance, programming model, workflow},
}


@INPROCEEDINGS{DelEP2006,
author={O. Delannoy and F. Emad and S. Petiton},
booktitle={2006 7th IEEE/ACM International Conference on Grid Computing},
title={Workflow Global Computing with YML},
year={2006},
volume={},
number={},
pages={25-32},
keywords={grid computing;iterative methods;linear algebra;middleware;peer-to-peer computing;programming environments;resource allocation;specification languages;YML;YvetteML;data migration;grid resources;human-grid middleware interface;iterative linear algebra;parallel application;peer to peer middleware;resource allocation;workflow global computing;workflow language;workflow programming environment;Application software;Concurrent computing;High performance computing;Iterative methods;Large-scale systems;Libraries;Linear algebra;Middleware;Programming environments;Runtime},
doi={10.1109/ICGRID.2006.310994},
ISSN={2152-1085},
month={Sept},}


@INPROCEEDINGS{ChDPW1992,
author={J. Choi and J. J. Dongarra and R. Pozo and D. W. Walker},
booktitle={[Proceedings 1992] The Fourth Symposium on the Frontiers of Massively Parallel Computation},
title={ScaLAPACK: a scalable linear algebra library for distributed memory concurrent computers},
year={1992},
volume={},
number={},
pages={120-127},
keywords={distributed memory systems;linear algebra;mathematics computing;object-oriented programming;performance evaluation;software packages;ScaLAPACK;scalable linear algebra library;distributed memory concurrent computers;software package;matrix computations;Level 3 BLAS;object-oriented interface;library routines;square block scattered decomposition;distributed memory version;right-looking LU factorization algorithm;Intel Delta multicomputer;performance;Linear algebra;Concurrent computing;Distributed computing;Software libraries;Scalability;Software packages;Brillouin scattering;Algorithm design and analysis;Sparse matrices;Contracts},
doi={10.1109/FMPC.1992.234898},
ISSN={},
month={Oct},}


@article{AABBC2016,
  author    = {Mart{\'{\i}}n Abadi and
               Ashish Agarwal and
               Paul Barham and
               Eugene Brevdo and
               Zhifeng Chen and
               Craig Citro and
               Gregory S. Corrado and
               Andy Davis and
               Jeffrey Dean and
               Matthieu Devin and
               Sanjay Ghemawat and
               Ian J. Goodfellow and
               Andrew Harp and
               Geoffrey Irving and
               Michael Isard and
               Yangqing Jia and
               Rafal J{\'{o}}zefowicz and
               Lukasz Kaiser and
               Manjunath Kudlur and
               Josh Levenberg and
               Dan Man{\'{e}} and
               Rajat Monga and
               Sherry Moore and
               Derek Gordon Murray and
               Chris Olah and
               Mike Schuster and
               Jonathon Shlens and
               Benoit Steiner and
               Ilya Sutskever and
               Kunal Talwar and
               Paul A. Tucker and
               Vincent Vanhoucke and
               Vijay Vasudevan and
               Fernanda B. Vi{\'{e}}gas and
               Oriol Vinyals and
               Pete Warden and
               Martin Wattenberg and
               Martin Wicke and
               Yuan Yu and
               Xiaoqiang Zheng},
  title     = {TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed
               Systems},
  journal   = {CoRR},
  volume    = {abs/1603.04467},
  year      = {2016},
  url       = {http://arxiv.org/abs/1603.04467},
  archivePrefix = {arXiv},
  eprint    = {1603.04467},
  timestamp = {Wed, 07 Jun 2017 14:40:20 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/AbadiABBCCCDDDG16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@INPROCEEDINGS{BCCDD1996,
author={L. S. Blackford and J. Choi and A. Cleary and J. Demmel and I. Dhillon and J. Dongarra and S. Hammarling and G. Henry and A. Petitet and K. Stanley and D. Walker and R. C. Whaley},
booktitle={Proceedings of the 1996 ACM/IEEE Conference on Supercomputing},
title={ScaLAPACK: A Portable Linear Algebra Library for Distributed Memory Computers - Design Issues and Performance},
year={1996},
volume={},
number={},
pages={5-5},
keywords={math libraries;numerical linear algebra;parallel computing;Computer science;Contracts;Distributed computing;Laboratories;Least squares methods;Libraries;Linear algebra;Portable computers;Software performance;Standards development;math libraries;numerical linear algebra;parallel computing},
doi={10.1109/SUPERC.1996.183513},
ISSN={},
month={},
}


@article{BayKS1983,
author = {Edip Baysal and Dan D. Kosloff and John W. C. Sherwood},
title = {Reverse time migration},
journal = {GEOPHYSICS},
volume = {48},
number = {11},
pages = {1514-1524},
year = {1983},
doi = {10.1190/1.1441434},
URL = {https://doi.org/10.1190/1.1441434},
eprint = {https://doi.org/10.1190/1.1441434}
}


@Inbook{CKRWW2007,
author="Couvares, Peter
and Kosar, Tevfik
and Roy, Alain
and Weber, Jeff
and Wenger, Kent",
editor="Taylor, Ian J.
and Deelman, Ewa
and Gannon, Dennis B.
and Shields, Matthew",
title="Workflow Management in Condor",
bookTitle="Workflows for e-Science: Scientific Workflows for Grids",
year="2007",
publisher="Springer London",
address="London",
pages="357--375",
abstract="The Condor project began in 1988 and has evolved into a feature-rich batch system that targets high-throughput computing; that is, Condor ([262], [414]) focuses on providing reliable access to computing over long periods of time instead of highly tuned, high-performance computing for short periods of time or a small number of applications.",
isbn="978-1-84628-757-2",
doi="10.1007/978-1-84628-757-2_22",
url="https://doi.org/10.1007/978-1-84628-757-2_22"
}


@article{DaguM1998,
    author = {Dagum, Leonardo and Menon, Ramesh},
    title = {OpenMP: An Industry-Standard API for Shared-Memory Programming},
    journal = {IEEE Comput. Sci. Eng.},
    issue_date = {January 1998},
    volume = {5},
    number = {1},
    month = jan,
    year = {1998},
    issn = {1070-9924},
    pages = {46--55},
    numpages = {10},
    url = {https://doi.org/10.1109/99.660313},
    doi = {10.1109/99.660313},
    acmid = {615542},
    publisher = {IEEE Computer Society Press},
    address = {Los Alamitos, CA, USA},
}


@INPROCEEDINGS{MelTP1999,
author={N. Melab and E. G. Talbi and S. Petiton},
booktitle={Proceedings 13th International Parallel Processing Symposium and 10th Symposium on Parallel and Distributed Processing. IPPS/SPDP 1999},
title={A parallel adaptive version of the block-based Gauss-Jordan algorithm},
year={1999},
volume={},
number={},
pages={350-354},
keywords={parallel algorithms;workstation clusters;Ethernet network;Gigaswitch network;MARS;SUN-Sparc4 workstations;adaptive folding;block-based Gauss-Jordan algorithm;cluster of DEC/ALPHA processors;numerical analysis;parallel adaptive version;Fault tolerance;Gaussian processes;Ice;LAN interconnection;Mars;Network topology;Numerical analysis;Parallel programming;Programming environments;Workstations},
doi={10.1109/IPPS.1999.760499},
ISSN={},
month={Apr},
}


@techreport{CDCYB1999,
  title={Introduction to UPC and language specification},
  author={Carlson, William W and Draper, Jesse M and Culler, David E and Yelick, Kathy and Brooks, Eugene and Warren, Karen},
  year={1999},
  institution={Technical Report CCS-TR-99-157, IDA Center for Computing Sciences}
}

@INPROCEEDINGS{DBBHD2014,
author={A. {Danalis} and G. {Bosilca} and A. {Bouteiller} and T. {Herault} and J. {Dongarra}},
booktitle={2014 Fourth International Workshop on Domain-Specific Languages and High-Level Frameworks for High Performance Computing},
title={PTG: An Abstraction for Unhindered Parallelism},
year={2014},
volume={},
number={},
pages={21-30},
keywords={message passing;parallel programming;PTG abstraction;unhindered parallelism abstraction;heterogeneous computing resource;HPC;high performance computing;exascale computing;programming paradigm;coarse grain parallelism;data movement;message passing;data-flow based programming;parameterized task graph abstraction;PaRSEC system;data-flow task-based runtime system;MPI application;MPI library;message passing interface;Programming;Runtime;Parallel processing;Hardware;Load modeling;Message passing;Computational modeling},
doi={10.1109/WOLFHPC.2014.8},
ISSN={},
month={Nov},}


@inproceedings{HoHBD2017,
 author = {Hoque, Reazul and Herault, Thomas and Bosilca, George and Dongarra, Jack},
 title = {Dynamic Task Discovery in PaRSEC: A Data-flow Task-based Runtime},
 booktitle = {Proceedings of the 8th Workshop on Latest Advances in Scalable Algorithms for Large-Scale Systems},
 series = {ScalA '17},
 year = {2017},
 isbn = {978-1-4503-5125-6},
 location = {Denver, Colorado},
 pages = {6:1--6:8},
 articleno = {6},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/3148226.3148233},
 doi = {10.1145/3148226.3148233},
 acmid = {3148233},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {PaRSEC, data-flow, dynamic task-graph, task-based runtime},
}


@INPROCEEDINGS{BBDHL2011,
author={G. {Bosilca} and A. {Bouteiller} and A. {Danalis} and T. {Herault} and P. {Lemarinier} and J. {Dongarra}},
booktitle={2011 IEEE International Symposium on Parallel and Distributed Processing Workshops and Phd Forum},
title={DAGuE: A Generic Distributed DAG Engine for High Performance Computing},
year={2011},
volume={},
number={},
pages={1151-1158},
keywords={cache storage;directed graphs;linear algebra;matrix decomposition;parallel architectures;processor scheduling;programming environments;scientific information systems;DAGuE;generic distributed DAG engine;high performance computing;frenetic development;state-of-the-art programming environments;scientific computing community;architecture aware scheduling;micro-tasks management;distributed many-core heterogeneous architectures;direct acyclic graph;data dependency;problem-size independent format;totally distributed fashion;fully-distributed scheduler;cache awareness;data-locality;task priority;micro-benchmarks;linear algebra factorization;Engines;Tiles;Benchmark testing;Instruction sets;Niobium;Processor scheduling;Computer architecture},
doi={10.1109/IPDPS.2011.281},
ISSN={1530-2075},
month={May},}


@article{DVJRC2015,
author={Ewa Deelman and Karan Vahi and Gideon Juve and Mats Rynge and Scott Callaghan and Philip J Maechling and Rajiv Mayani and Weiwei Chen and Ferreira da Silva, Rafael and Miron Livny and Kent Wenger},
url={http://pegasus.isi.edu/publications/2014/2014-fgcs-deelman.pdf},
title={Pegasus: a Workflow Management System for Science Automation},
journal={Future Generation Computer Systems},
volume={46},
pages={17--35},
year={2015},
note={Funding Acknowledgements: NSF ACI SDCI 0722019, NSF ACI SI2-SSI 1148515 and NSF OCI-1053575},
doi={10.1016/j.future.2014.10.008}
}


@article{DSSBG2005,
author={Ewa Deelman and Gurmeet Singh and Mei-Hui Su and James Blythe and Yolanda Gil and Carl Kesselman and Gaurang Mehta and Karan Vahi and G. Bruce Berriman and John Good and Anastasia Laity and Joseph C. Jacob and Daniel S. Katz},
url={http://pegasus.isi.edu/publications/Sci.pdf},
title={Pegasus: a Framework for Mapping Complex Scientific Workflows onto Distributed Systems},
journal={Scientific Programming Journal},
volume={13},
number={3},
pages={219-237},
year={2005}
}

@inproceedings{KHASF2014,
 author = {Kaiser, Hartmut and Heller, Thomas and Adelstein-Lelbach, Bryce and Serio, Adrian and Fey, Dietmar},
 title = {HPX: A Task Based Programming Model in a Global Address Space},
 booktitle = {Proceedings of the 8th International Conference on Partitioned Global Address Space Programming Models},
 series = {PGAS '14},
 year = {2014},
 isbn = {978-1-4503-3247-7},
 location = {Eugene, OR, USA},
 pages = {6:1--6:11},
 articleno = {6},
 numpages = {11},
 url = {http://doi.acm.org/10.1145/2676870.2676883},
 doi = {10.1145/2676870.2676883},
 acmid = {2676883},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Exascale, Global Address Space, High Performance Computing, Parallel Runtime Systems, Programming Models},
}

@misc{KAHBS2019,
  author       = {Hartmut Kaiser and
                  Bryce Adelstein Lelbach aka wash and
                  Thomas Heller and
                  Agustín Bergé and
                  Mikael Simberg and
                  John Biddiscombe and
                  Anton Bikineev and
                  Grant Mercer and
                  Andreas Schäfer and
                  Adrian Serio and
                  Taeguk Kwon and
                  Kevin Huck and
                  Jeroen Habraken and
                  Matthew Anderson and
                  Marcin Copik and
                  Steven R. Brandt and
                  Martin Stumpf and
                  Daniel Bourgeois and
                  Denis Blank and
                  Shoshana Jakobovits and
                  Vinay Amatya and
                  Lars Viklund and
                  Zahra Khatami and
                  Devang Bacharwar and
                  Shuangyang Yang and
                  Erik Schnetter and
                  Patrick Diehl and
                  Nikunj Gupta and
                  Bibek Wagle and
                  Christopher},
  title        = {{STEllAR-GROUP/hpx: HPX V1.2.1: The C++ Standards
                   Library for Parallelism and Concurrency}},
  month        = feb,
  year         = 2019,
  doi          = {10.5281/zenodo.2573213},
  url          = {https://doi.org/10.5281/zenodo.2573213}
}

@article{PRBBF2016,
author = {William L. Poehlman and Mats Rynge and Chris Branton and D. Balamurugan and Frank A. Feltus},
title ={OSG-GEM: Gene Expression Matrix Construction Using the Open Science Grid},
journal = {Bioinformatics and Biology Insights},
volume = {10},
number = {},
pages = {BBI.S38193},
year = {2016},
doi = {10.4137/BBI.S38193},
URL = {https://doi.org/10.4137/BBI.S38193},
eprint = {https://doi.org/10.4137/BBI.S38193},
}

@INPROCEEDINGS{SLTBA2015,
author={E. {Slaughter} and W. {Lee} and S. {Treichler} and M. {Bauer} and A. {Aiken}},
booktitle={SC '15: Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
title={Regent: a high-productivity programming language for HPC with logical regions},
year={2015},
volume={},
number={},
pages={1-12},
keywords={data flow analysis;parallel processing;program compilers;programming languages;Regent;programming language;high performance computing;HPC;logical region;serial execution;parallel machine;distributed machine;Legion;asynchronous task-based model;compiler optimization;dynamic overhead minimization;runtime system;Programming;Runtime;Semiconductor optical amplifiers;Image color analysis;Reactive power;Optimization;C++ languages},
doi={10.1145/2807591.2807629},
ISSN={2167-4337},
month={Nov},}


@techreport{Petit1991,
     title = {{Massively Parallel Sparse Matrix Computation for Iterative Methods}},
     author = {Serge G. Petiton},
     year = {1991},
     institution = {Yale University, Department of Computer Science},
}

@ARTICLE{HacBG1971,
author={G. {Hachtel} and R. {Brayton} and F. {Gustavson}},
journal={IEEE Transactions on Circuit Theory},
title={The Sparse Tableau Approach to Network Analysis and Design},
year={1971},
volume={18},
number={1},
pages={101-113},
keywords={Computer-aided circuit design;Nonlinear networks;Optimization techniques;Sparse-matrix methods;Sparse matrices;Design optimization;Computer networks;Differential equations;Voltage;Capacitance;Roundoff errors;Nonlinear equations;Design automation;Computational modeling},
doi={10.1109/TCT.1971.1083223},
ISSN={},
month={01},}

@Inbook{Gusta1972,
author="Gustavson, Fred G.",
editor="Rose, Donald J.
and Willoughby, Ralph A.",
title="Some Basic Techniques for Solving Sparse Systems of Linear Equations",
bookTitle="Sparse Matrices and their Applications: Proceedings of a Symposium on Sparse Matrices and Their Applications, held September 9--10, 1971, at the IBM Thomas J. Watson Research Center, Yorktown Heights, New York, and sponsored by the Office of Naval Research, the National Science Foundation, IBM World Trade Corporation, and the IBM Research Mathematical Sciences Department.",
year="1972",
publisher="Springer US",
address="Boston, MA",
pages="41--52",
abstract="The main character of this paper is tutorial. Yet it will serve as a survey of some of the sparse matrix methods used for solving Ax=b. And, in some sense the results are new.",
isbn="978-1-4615-8675-3",
doi="10.1007/978-1-4615-8675-3_4",
url="https://doi.org/10.1007/978-1-4615-8675-3_4"
}

@article{FeWPS1993,
author = {Ferng, W. and Wu, Kesheng and Petiton, Serge and Saad, Yousef},
year = {1993},
month = {03},
pages = {},
title = {Basic Sparse Matrix Computations On Massively Parallel Computers}
}


@article{Saad1990,
author = {Saad, Youcef},
year = {1990},
month = {06},
pages = {},
title = {SPARSKIT: A basic tool kit for sparse matrix computations}
}

@article{BramK2018,
  title={Computing the sparse matrix vector product using block-based kernels without zero padding on processors with AVX-512 instructions},
  author={Bramas, B{\'e}renger and Kus, Pavel},
  journal={PeerJ Computer Science},
  volume={4},
  pages={e151},
  year={2018},
  publisher={PeerJ Inc.}
}

@InProceedings{YeCP2015,
author="Ye, Fan
and Calvin, Christophe
and Petiton, Serge G.",
editor="Dayd{\'e}, Michel
and Marques, Osni
and Nakajima, Kengo",
title="A Study of SpMV Implementation Using MPI and OpenMP on Intel Many-Core Architecture",
booktitle="High Performance Computing for Computational Science -- VECPAR 2014",
year="2015",
publisher="Springer International Publishing",
address="Cham",
pages="43--56",
abstract="The Sparse Matrix-Vector Multiplication (SpMV) is fundamental to a broad spectrum of scientific and engineering applications, such as many iterative numerical methods. The widely used Compressed Sparse Row (CSR) sparse matrix storage format was chosen to carry on this study for sustainability and reusability reasons.",
isbn="978-3-319-17353-5"
}

@INPROCEEDINGS{HuguP2010,
author={M. R. {Hugues} and S. G. {Petiton}},
booktitle={2010 IEEE 12th International Conference on High Performance Computing and Communications (HPCC)},
title={Sparse Matrix Formats Evaluation and Optimization on a GPU},
year={2010},
volume={},
number={},
pages={122-129},
keywords={computer graphic equipment;coprocessors;iterative methods;multiprocessing systems;parallel programming;sparse matrices;sparse matrix format evaluation;GPU;sparse matrix format optimization;data parallel programming model;massive multicore;linear algebra;sparse matrix vector product;iterative method;SpMV kernel;Arrays;Sparse matrices;Graphics processing unit;Indexes;Instruction sets;Artificial neural networks;Finite element methods;Sparse Format;SpMV;GPU;Many-Core;Data Parallel Programming},
doi={10.1109/HPCC.2010.85},
ISSN={null},
month={Sep.},}

@inproceedings{PetiE1996,
 author = {Petiton, Serge G. and Emad, Nahid},
 title = {A Data Parallel Scientific Computing Introduction},
 booktitle = {The Data Parallel Programming Model: Foundations, HPF Realization, and Scientific Applications},
 year = {1996},
 isbn = {3-540-61736-1},
 pages = {45--64},
 numpages = {20},
 url = {http://dl.acm.org/citation.cfm?id=647429.723576},
 acmid = {723576},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
}

@InProceedings{GurhP2020,
author="Gurhem, J{\'e}r{\^o}me
and Petiton, Serge G.",
editor="Krzhizhanovskaya, Valeria V.
and Z{\'a}vodszky, G{\'a}bor
and Lees, Michael H.
and Dongarra, Jack J.
and Sloot, Peter M. A.
and Brissos, S{\'e}rgio
and Teixeira, Jo{\~a}o",
title="A Current Task-Based Programming Paradigms Analysis",
booktitle="Computational Science -- ICCS 2020",
year="2020",
publisher="Springer International Publishing",
address="Cham",
pages="203--216",
abstract="Task-based paradigm models can be an alternative to MPI. The user defines atomic tasks with a defined input and output with the dependencies between them. Then, the runtime can schedule the tasks and data migrations efficiently over all the available cores while reducing the waiting time between tasks. This paper focus on comparing several task-based programming models between themselves using the LU factorization as benchmark.",
ISBN="978-3-030-50426-7",
}

@article{DonLP2003,
author = {Dongarra, Jack J. and Luszczek, Piotr and Petitet, Antoine},
title = {The LINPACK Benchmark: past, present and future},
journal = {Concurrency and Computation: Practice and Experience},
volume = {15},
number = {9},
pages = {803-820},
keywords = {benchmarking, BLAS, high-performance computing, HPL, linear algebra, LINPACK, TOP500},
doi = {10.1002/cpe.728},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.728},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/cpe.728},
abstract = {Abstract This paper describes the LINPACK Benchmark and some of its variations commonly used to assess the performance of computer systems. Aside from the LINPACK Benchmark suite, the TOP500 and the HPL codes are presented. The latter is frequently used to obtained results for TOP500 submissions. Information is also given on how to interpret the results of the benchmark and how the results fit into the performance evaluation process. Copyright © 2003 John Wiley \& Sons, Ltd.},
year = {2003}
}

@article{Parle1981,
author = {Parlett, B. N.},
title = {LINPACK Users’ Guide (J. J. Dongarra, J. R. Bunch, C. B. Moler and G. W. Stewart)},
journal = {SIAM Review},
volume = {23},
number = {1},
pages = {126-128},
year = {1981},
doi = {10.1137/1023033},
URL = {
        https://doi.org/10.1137/1023033
},
eprint = {
        https://doi.org/10.1137/1023033
}

}

@BOOK{ABBBD1999,
      AUTHOR = {Anderson, E. and Bai, Z. and Bischof, C. and
                Blackford, S. and Demmel, J. and Dongarra, J. and
                Du Croz, J. and Greenbaum, A. and Hammarling, S. and
                McKenney, A. and Sorensen, D.},
      TITLE = {{LAPACK} Users' Guide},
      EDITION = {Third},
      PUBLISHER = {Society for Industrial and Applied Mathematics},
      YEAR = {1999},
      ADDRESS = {Philadelphia, PA},
      ISBN = {0-89871-447-8 (paperback)}
}

@article{GoluL1983,
  title={Matrix Computations},
  author={Golub, Gene H and Van Loan, Charles F},
  journal={Johns Hopkins University, Baltimore},
  year={1983}
}

@inproceedings{GeCPJ2000,
author = {Germain, J. Davison de St. and McCorquodale, John and Parker, Steven G. and Johnson, Christopher R.},
title = {Uintah: A Massively Parallel Problem Solving Environment},
year = {2000},
isbn = {0769507832},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {This paper describes Uintah, a component-based visual problem-solving environment (PSE) that is designed to specifically address the unique problems of massively parallel computation on terascale computing platforms. Uintah supports the entire life cycle of scientific applications by allowing scientific programmers to quickly and easily develop new techniques, debug new implementations, and apply known algorithms to solve novel problems. Uintah is built on three principles: 1) As much as possible, the complexities of parallel execution should be handled for the scientist, 2) software should be reusable at the component level, and 3) scientists should be able to dynamically steer and visualize their simulation results as the simulation executes. To provide this functionality, Uintah builds upon the best features of the SCIRun PSE and the DoE Common Component Architecture (CCA).},
booktitle = {Proceedings of the 9th IEEE International Symposium on High Performance Distributed Computing},
pages = {33},
numpages = {1},
series = {HPDC '00}
}

@article{CDOPW1996,
author = {Choi, Jaeyoung and Dongarra, Jack J. and Ostrouchov, L. Susan and Petitet, Antoine P. and Walker, David W. and Whaley, R. Clint},
title = {The Design and Implementation of the ScaLAPACK LU, QR, and Cholesky Factorization Routines},
year = {1996},
issue_date = {August 1996},
publisher = {IOS Press},
address = {NLD},
volume = {5},
number = {3},
url = {https://doi.org/10.1155/1996/483083},
doi = {10.1155/1996/483083},
journal = {Sci. Program.},
month = aug,
pages = {173–184},
numpages = {12}
}

@article{DemHS1995,
author = {Demmel, James W. and Higham, Nicholas J. and Schreiber, Robert S.},
title = {Stability of block LU factorization},
journal = {Numerical Linear Algebra with Applications},
volume = {2},
number = {2},
pages = {173-190},
keywords = {block algorithm, LAPACK, level 3 BLAS, iterative refinement, LU factorization, backward error analysis, block diagonal dominance},
doi = {10.1002/nla.1680020208},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/nla.1680020208},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/nla.1680020208},
abstract = {Many of the currently popular ‘block algorithms’ are scalar algorithms in which the operations have been grouped and reordered into matrix operations. One genuine block algorithm in practical use is block LU factorization, and this has recently been shown by Demmel and Higham to be unstable in general. It is shown here that block LU factorization is stable if A is block diagonally dominant by columns. Moreover, for a general matrix the level of instability in block LU factorization can be bounded in terms of the condition number K(A) and the growth factor for Gaussian elimination without pivoting. A consequence is that block LU factorization is stable for a matrix A that is symmetric positive definite or point diagonally dominant by rows or columns as long as A is well-conditioned.},
year = {1995}
}

@incollection{BuncR1976,
title = "BLOCK METHODS FOR SOLVING SPARSE LINEAR SYSTEMS",
editor = "JAMES R. BUNCH and DONALD J. ROSE",
booktitle = "Sparse Matrix Computations",
publisher = "Academic Press",
pages = "39 - 58",
year = "1976",
isbn = "978-0-12-141050-6",
doi = "https://doi.org/10.1016/B978-0-12-141050-6.50008-8",
url = "http://www.sciencedirect.com/science/article/pii/B9780121410506500088",
author = "James R. Bunch",
abstract = "Graph-theoretic techniques for analyzing the solution of large sparse systems of linear equations by partitioning and using block methods are developed. Questions concerning stability of block methods are discussed."
}

@InProceedings{BissV1988,
author="Bisseling, Rob H.
and van de Vorst, Johannes G. G.",
editor="van Zee, G. A.
and van de Vorst, J. G. G.",
title="Parallel LU decomposition on a transputer network",
booktitle="Parallel Computing 1988",
year="1989",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="61--77",
abstract="A parallel algorithm is derived for LU decomposition with partial pivoting on a local-memory multiprocessor. A general Cartesian data distribution scheme is presented which contains many of the existing distribution schemes as special cases. This scheme is used to prove optimality of load balance for the grid distribution. Experimental results of an implementation of the algorithm in occam-2 on a square mesh of 36 transputers show an efficiency of 88{\%} and a speed of 21.5 Mflop/s for a matrix of size n=1000.",
isbn="978-3-540-46689-5"
}

@article{Velde1990,
author = {van de Velde, Eric F.},
title = {Experiments with multicomputer LU-decomposition},
journal = {Concurrency: Practice and Experience},
volume = {2},
number = {1},
pages = {1-26},
doi = {10.1002/cpe.4330020102},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.4330020102},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/cpe.4330020102},
abstract = {We present a new concurrent LU-decomposition algorithm based on implicit pivoting of both rows and columns. This algorithm is, to a large extent, independent of the distribution of the matrix over the concurrent processes. As a result, it can be used in programs with dynamically varying data distributions. Another advantage is that most pivoting strategies are easily incorporated. We also introduce two new, intrinsically concurrent, pivoting strategies: multirow and multicolumn pivoting. With this program, we study the performance of concurrent LU-decomposition as a function of data distribution and pivoting strategy. We show that LU-decomposition with some pivoting strategies is both faster and numerically more stable than LU-decomposition without pivoting. Experimental evidence on the Symult 2010 and the iPSC/2 shows that, for performance considerations, pivoting is equivalent to randomizing the data distribution.},
year = {1990}
}

@article{Saad1986,
title = "Communication complexity of the Gaussian elimination algorithm on multiprocessors",
journal = "Linear Algebra and its Applications",
volume = "77",
pages = "315 - 340",
year = "1986",
issn = "0024-3795",
doi = "https://doi.org/10.1016/0024-3795(86)90174-6",
url = "http://www.sciencedirect.com/science/article/pii/0024379586901746",
author = "Youcef Saad",
abstract = "This paper proposes a few lower bounds for communication complexity of the Gaussian elimination algorithm on multiprocessors. Three types of architectures are considered: a bus architecture, a nearest neighbor ring network, and a nearest neighbor grid network. It is shown that for the bus and the ring architectures, the minimum communication time is O(N2), independent of the number of processors, while for the grid it is reduced to O(kbuilt-12N2)+O(kbuilt12N) for a lock step Gaussian elimination algorithm, and to O(kbuilt-12N2)+O(kbuilt12) for any pipelined Gaussian elimination algorithm, where k is the total number of processors. The practical implications of these bounds are discussed."
}

@article{GeorC1987,
title={Gaussian elimination with partial pivoting and load balancing on a multiprocessor},
author={E. Chu and A. George},
journal={Parallel Comput.},
year={1987},
volume={5},
pages={65-74}
}

@incollection{Attaw2012,
title = "Chapter 12 - Matrix Representation of Linear Algebraic Equations",
editor = "Stormy Attaway",
booktitle = "Matlab (Second Edition)",
publisher = "Butterworth-Heinemann",
edition = "Second Edition",
address = "Boston",
pages = "367 - 399",
year = "2012",
isbn = "978-0-12-385081-2",
doi = "https://doi.org/10.1016/B978-0-12-385081-2.00012-0",
url = "http://www.sciencedirect.com/science/article/pii/B9780123850812000120",
author = "Stormy Attaway"
}

@article{Saad1989,
title={Krylov subspace methods on supercomputers},
author={Y. Saad},
journal={Siam Journal on Scientific and Statistical Computing},
year={1989},
volume={10},
pages={1200-1232}
}

@book{Saad2003,
author = {Saad, Yousef},
title = {Iterative Methods for Sparse Linear Systems},
publisher = {Society for Industrial and Applied Mathematics},
year = {2003},
doi = {10.1137/1.9780898718003},
address = {},
edition   = {Second},
URL = {https://epubs.siam.org/doi/abs/10.1137/1.9780898718003},
eprint = {https://epubs.siam.org/doi/pdf/10.1137/1.9780898718003}
}

@article{RidiS2002,
  title={Pagerank uncovered},
  author={Ridings, Chris and Shishigin, Mike},
  journal={Technical Paper for the Search Engine Optimization Online Community},
  year={2002}
}

@techreport{MPIForum,
author = {Forum, Message P},
title = {MPI: A Message-Passing Interface Standard},
year = {1994},
publisher = {University of Tennessee},
address = {USA},
abstract = {The Message Passing Interface Forum (MPIF), with participation from over 40 organizations, has been meeting since November 1992 to discuss and define a set of library standards for message passing. MPIF is not sanctioned or supported by any official standards organization. The goal of the Message Passing Interface, simply stated, is to develop a widely used standard for writing message-passing programs. As such the interface should establish a practical, portable, efficient and flexible standard for message passing. , This is the final report, Version 1.0, of the Message Passing Interface Forum. This document contains all the technical features proposed for the interface. This copy of the draft was processed by LATEX on April 21, 1994. , Please send comments on MPI to mpi-comments@cs.utk.edu. Your comment will be forwarded to MPIF committee members who will attempt to respond.}
}

@article{SoGLK2016,
   title={Novel graph processor architecture, prototype system, and results},
   ISBN={9781509035250},
   url={http://dx.doi.org/10.1109/HPEC.2016.7761635},
   DOI={10.1109/hpec.2016.7761635},
   journal={2016 IEEE High Performance Extreme Computing Conference (HPEC)},
   publisher={IEEE},
   author={Song, William S. and Gleyzer, Vitaliy and Lomakin, Alexei and Kepner, Jeremy},
   year={2016},
   month={Sep}
}

@book{KepnG2011,
author = {Kepner, Jeremy and Gilbert, John},editor = {Jeremy Kepner and John Gilbert},
title = {Graph Algorithms in the Language of Linear Algebra},
publisher = {Society for Industrial and Applied Mathematics},
year = {2011},
doi = {10.1137/1.9780898719918},
address = {},
edition   = {},
URL = {https://epubs.siam.org/doi/abs/10.1137/1.9780898719918},
eprint = {https://epubs.siam.org/doi/pdf/10.1137/1.9780898719918}
}

@INPROCEEDINGS{PageK2018,
author={B. A. {Page} and P. M. {Kogge}},
booktitle={2018 International Conference on High Performance Computing Simulation (HPCS)},
title={Scalability of Hybrid Sparse Matrix Dense Vector (SpMV) Multiplication},
year={2018},
volume={},
number={},
pages={406-414},
keywords={matrix multiplication;parallel processing;sparse matrices;vectors;hybrid sparse matrix dense vector;memory bandwidth;hybrid SpMV codes;strong scalability;Sparse matrices;Bandwidth;Protocols;Message systems;Hardware;Scalability;Indexes},
doi={10.1109/HPCS.2018.00072},
ISSN={},
month={July},}

@phdthesis{Vuduc2003phd,
  author       = {R. W. Vuduc},
  title        = {Automatic performance tuning of sparse matrix kernels},
  school       = {University of California, Berkeley},
  year         = 2003,
}

@phdthesis{Im2000phd,
  author       = {E-J. Im},
  title        = {Optimizing the performance of sparse matrix-vector multiplication},
  school       = {EECS Department, University of California, Berkeley},
  year         = 2000,
}

@ARTICLE{Toledo1997,
  author={S. {Toledo}},
  journal={IBM Journal of Research and Development},
  title={Improving the memory-system performance of sparse-matrix vector multiplication},
  year={1997},
  volume={41},
  number={6},
  pages={711-725},}

@inproceedings{PinaH1999,
author = {Pinar, Ali and Heath, Michael T.},
title = {Improving Performance of Sparse Matrix-Vector Multiplication},
year = {1999},
isbn = {1581130910},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/331532.331562},
doi = {10.1145/331532.331562},
booktitle = {Proceedings of the 1999 ACM/IEEE Conference on Supercomputing},
pages = {30–es},
numpages = {9},
location = {Portland, Oregon, USA},
series = {SC '99}
}

@article{NiBGS2008,
    author = {Nickolls, John and Buck, Ian and Garland, Michael and Skadron, Kevin},
    title = {Scalable Parallel Programming with CUDA},
    journal = {Queue},
    issue_date = {March/April 2008},
    volume = {6},
    number = {2},
    month = mar,
    year = {2008},
    issn = {1542-7730},
    pages = {40--53},
    numpages = {14},
    url = {http://doi.acm.org/10.1145/1365490.1365500},
    doi = {10.1145/1365490.1365500},
    acmid = {1365500},
    publisher = {ACM},
    address = {New York, NY, USA},
}

@book{Shane2012,
author = {Cook, Shane},
title = {CUDA Programming: A Developer’s Guide to Parallel Computing with GPUs},
year = {2012},
isbn = {9780124159334},
publisher = {Morgan Kaufmann Publishers Inc.},
address = {San Francisco, CA, USA},
edition = {1st}
}

@article{WOVSY2009,
title = "Optimization of sparse matrix vector multiplication on emerging multicore platforms",
journal = "Parallel Computing",
volume = "35",
number = "3",
pages = "178 - 194",
year = "2009",
note = "Revolutionary Technologies for Acceleration of Emerging Petascale Applications",
issn = "0167-8191",
doi = "https://doi.org/10.1016/j.parco.2008.12.006",
url = "http://www.sciencedirect.com/science/article/pii/S0167819108001403",
author = "Samuel Williams and Leonid Oliker and Richard Vuduc and John Shalf and Katherine Yelick and James Demmel",
keywords = "Multicore, Sparse, Performance, Autotuning, HPC, Cell, Niagara",
abstract = "We are witnessing a dramatic change in computer architecture due to the multicore paradigm shift, as every electronic device from cell phones to supercomputers confronts parallelism of unprecedented scale. To fully unleash the potential of these systems, the HPC community must develop multicore specific-optimization methodologies for important scientific computations. In this work, we examine sparse matrixâvector multiply (SpMV) â one of the most heavily used kernels in scientific computing â across a broad spectrum of multicore designs. Our experimental platform includes the homogeneous AMD quad-core, AMD dual-core, and Intel quad-core designs, the heterogeneous STI Cell, as well as one of the first scientific studies of the highly multithreaded Sun Victoria Falls (a Niagara2 SMP). We present several optimization strategies especially effective for the multicore environment, and demonstrate significant performance improvements compared to existing state-of-the-art serial and parallel SpMV implementations. Additionally, we present key insights into the architectural trade-offs of leading multicore design strategies, in the context of demanding memory-bound numerical algorithms."
}

@inproceedings{LiSCD2013,
 author = {Liu, Xing and Smelyanskiy, Mikhail and Chow, Edmond and Dubey, Pradeep},
 title = {Efficient Sparse Matrix-vector Multiplication on x86-based Many-core Processors},
 booktitle = {Proceedings of the 27th International ACM Conference on International Conference on Supercomputing},
 series = {ICS '13},
 year = {2013},
 isbn = {978-1-4503-2130-3},
 location = {Eugene, Oregon, USA},
 pages = {273--282},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2464996.2465013},
 doi = {10.1145/2464996.2465013},
 acmid = {2465013},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {esb format, intel many integrated core architecture (intel mic), intel xeon phi, knights corner, spmv},
}

@InProceedings{VuduM2005,
author="Vuduc, Richard W.
and Moon, Hyun-Jin",
editor="Yang, Laurence T.
and Rana, Omer F.
and Di Martino, Beniamino
and Dongarra, Jack",
title="Fast Sparse Matrix-Vector Multiplication by Exploiting Variable Block Structure",
booktitle="High Performance Computing and Communications",
year="2005",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="807--816",
abstract="We improve the performance of sparse matrix-vector multiplication(SpMV) on modern cache-based superscalar machines when the matrix structure consists of multiple, irregularly aligned rectangular blocks. Matrices from finite element modeling applications often have this structure. We split the matrix, A, into a sum, A1 + A2 + ... + As, where each term is stored in a new data structure we refer to as unaligned block compressed sparse row (UBCSR) format. A classical approach which stores A in a BCSR can also reduce execution time, but the improvements may be limited because BCSR imposes an alignment of the matrix non-zeros that leads to extra work from filled-in zeros. Combining splitting with UBCSR reduces this extra work while retaining the generally lower memory bandwidth requirements and register-level tiling opportunities of BCSR. We show speedups can be as high as 2.1{\texttimes} over no blocking, and as high as 1.8{\texttimes} over BCSR as used in prior work on a set of application matrices. Even when performance does not improve significantly, split UBCSR usually reduces matrix storage.",
isbn="978-3-540-32079-1"
}

@article{SWAAB2014,
author = {Marc Snir and Robert W Wisniewski and Jacob A Abraham and Sarita V Adve and Saurabh Bagchi and Pavan Balaji and Jim Belak and Pradip Bose and Franck Cappello and Bill Carlson and Andrew A Chien and Paul Coteus and Nathan A DeBardeleben and Pedro C Diniz and Christian Engelmann and Mattan Erez and Saverio Fazzari and Al Geist and Rinku Gupta and Fred Johnson and Sriram Krishnamoorthy and Sven Leyffer and Dean Liberty and Subhasish Mitra and Todd Munson and Rob Schreiber and Jon Stearley and Eric Van Hensbergen},
title ={Addressing failures in exascale computing},
journal = {The International Journal of High Performance Computing Applications},
volume = {28},
number = {2},
pages = {129-173},
year = {2014},
doi = {10.1177/1094342014522573},

URL = {
        https://doi.org/10.1177/1094342014522573

},
}

@inproceedings{CDMCE2005,
author = {Coarfa, Cristian and Dotsenko, Yuri and Mellor-Crummey, John and Cantonnet, François and El-Ghazawi, Tarek and Mohanti, Ashrujit and Yao, Yiyi and Chavarría-Miranda, Daniel},
year = {2005},
month = {01},
pages = {36-47},
title = {An evaluation of global address space languages: Co-array fortran and Unified Parallel C},
journal = {Proceedings of the ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, PPOPP},
doi = {10.1145/1065944.1065950}
}

@inproceedings{TFGBA2011,
author = {Tejedor, Enric and Farreras, Montse and Grove, David and Badia, Rosa M. and Almasi, Gheorghe and Labarta, Jesus},
title = {ClusterSs: A Task-Based Programming Model for Clusters},
year = {2011},
isbn = {9781450305525},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1996130.1996168},
doi = {10.1145/1996130.1996168},
abstract = {Programming for large-scale, multicore-based architectures requires adequate tools that offer ease of programming while not hindering application performance. StarSs is a family of parallel programming models based on automatic function level parallelism that targets productivity. StarSs deploys a data-flow model: it analyses dependencies between tasks and manages their execution, exploiting their concurrency as much as possible. We introduce Cluster Superscalar (ClusterSs), a new StarSs member designed to execute on clusters of SMPs. ClusterSs tasks are asynchronously created and assigned to the available resources with the support of the IBM APGAS runtime, which provides an efficient and portable communication layer based on one-sided communication.This short paper gives an overview of the ClusterSs design on top of APGAS, as well as the conclusions of a productivity study; in this study, ClusterSs was compared to the IBM X10 language, both in terms of programmability and performance. A technical report is available with the details.},
booktitle = {Proceedings of the 20th International Symposium on High Performance Distributed Computing},
pages = {267–268},
numpages = {2},
keywords = {parallel programming models, asynchronous execution, productivity, high-performance computing},
location = {San Jose, California, USA},
series = {HPDC '11}
}

@article{AuTNW2011,
author = {Augonnet, Cédric and Thibault, Samuel and Namyst, Raymond and Wacrenier, Pierre-André},
title = {StarPU: a unified platform for task scheduling on heterogeneous multicore architectures},
journal = {Concurrency and Computation: Practice and Experience},
volume = {23},
number = {2},
pages = {187-198},
keywords = {GPU, multicore, accelerator, scheduling, runtime system},
doi = "10.1002/cpe.1631",
year = {2011}
}

@INPROCEEDINGS{CalCZ2004,
author={D. {Callahan} and B. L. {Chamberlain} and H. P. {Zima}},
booktitle={Ninth International Workshop on High-Level Parallel Programming Models and Supportive Environments, 2004. Proceedings.},
title={The cascade high productivity language},
year={2004},
volume={},
number={},
pages={52-60},
keywords={parallel programming;object-oriented programming;high level languages;software architecture;message passing;user interfaces;cascade high productivity language;high end computing;parallel programming;message passing;fragmented programming model;object code performance;Chapel;HPCS project;system programming;high-level user interface;language technology;multithreading technology;locality awareness;object orientation;generic programming;architectural support;Productivity;Parallel programming;High performance computing;Object oriented programming;Computer architecture;Programming profession;Concurrent computing;Multithreading;Communication system control;Message passing},
doi={10.1109/HIPS.2004.1299190},
ISSN={},
month={April},}

@book{Hilli1989phd,
  title={The Connection Machine},
  author={Hillis, W.D.},
  isbn={9780262580977},
  lccn={85015318},
  series={ACM distinguished dissertations},
  url={https://books.google.fr/books?id=xg\_yaoC6CNEC},
  year={1989},
  publisher={Cambridge}
}

@article{GBDJM1995,
author = {Geist, Al and Beguelin, Adam and Dongarra, Jack and Jiang, Weicheng and Manchek, Robert and Sunderam, Vaidy},
year = {1995},
month = {11},
pages = {},
title = {Pvm 3 User's Guide And Reference Manual}
}

@book{KirkH2010,
  title={Programming Massively Parallel Processors: A Hands-on Approach},
  author={Kirk, D. and Hwu, W.},
  isbn={9780123814722},
  lccn={2009048259},
  series={Applications of GPU Computing Series},
  url={https://books.google.fr/books?id=x8oNlQEACAAJ},
  year={2010},
  publisher={Morgan Kaufmann Publishers}
}

@article{CGSDK2005,
author = {Charles, Philippe and Grothoff, Christian and Saraswat, Vijay and Donawa, Christopher and Kielstra, Allan and Ebcioglu, Kemal and von Praun, Christoph and Sarkar, Vivek},
title = {X10: An Object-Oriented Approach to Non-Uniform Cluster Computing},
year = {2005},
issue_date = {October 2005},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {40},
number = {10},
issn = {0362-1340},
url = {https://doi.org/10.1145/1103845.1094852},
doi = {10.1145/1103845.1094852},
journal = {SIGPLAN Not.},
month = oct,
pages = {519–538},
numpages = {20},
keywords = {Java, clocks, non-uniform cluster computing (NUCC), X10, productivity, data distribution, partitioned global address space (PGAS), scalability, multithreading, places, atomic blocks}
}

@inproceedings{HHMGT2016,
author = {Hamouda, Sara S. and Herta, Benjamin and Milthorpe, Josh and Grove, David and Tardieu, Olivier},
title = {Resilient X10 over MPI User Level Failure Mitigation},
year = {2016},
isbn = {9781450343862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2931028.2931030},
doi = {10.1145/2931028.2931030},
booktitle = {Proceedings of the 6th ACM SIGPLAN Workshop on X10},
pages = {18–23},
numpages = {6},
keywords = {MPI, X10, User Level Failure Mitigation, Resilience},
location = {Santa Barbara, CA, USA},
series = {X10 2016}
}

@INPROCEEDINGS{SlauA2019,
  author={E. {Slaughter} and A. {Aiken}},
  booktitle={2019 IEEE/ACM Parallel Applications Workshop, Alternatives To MPI (PAW-ATM)},
  title={Pygion: Flexible, Scalable Task-Based Parallelism with Python},
  year={2019},
  volume={},
  number={},
  pages={58-72},}

@inproceedings{BJKLR1995,
author = {Blumofe, Robert D. and Joerg, Christopher F. and Kuszmaul, Bradley C. and Leiserson, Charles E. and Randall, Keith H. and Zhou, Yuli},
title = {Cilk: An Efficient Multithreaded Runtime System},
year = {1995},
isbn = {0897917006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/209936.209958},
doi = {10.1145/209936.209958},
abstract = {Cilk (pronounced “silk”) is a C-based runtime system for multi-threaded parallel programming. In this paper, we document the efficiency of the Cilk work-stealing scheduler, both empirically and analytically. We show that on real and synthetic applications, the “work” and “critical path” of a Cilk computation can be used to accurately model performance. Consequently, a Cilk programmer can focus on reducing the work and critical path of his computation, insulated from load balancing and other runtime scheduling issues. We also prove that for the class of “fully strict” (well-structured) programs, the Cilk scheduler achieves space, time and communication bounds all within a constant factor of optimal.The Cilk runtime system  currently runs on the Connection Machine CM5 MPP, the Intel Paragon MPP, the Silicon Graphics Power Challenge SMP, and the MIT Phish network of workstations. Applications written in Cilk include protein folding, graphic rendering, backtrack search, and the *Socrates chess program, which won third prize in the 1994 ACM International Computer Chess Championship.},
booktitle = {Proceedings of the Fifth ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming},
pages = {207–216},
numpages = {10},
location = {Santa Barbara, California, USA},
series = {PPOPP '95}
}

@inproceedings{Leise2009,
author = {Leiserson, Charles E.},
title = {The Cilk++ Concurrency Platform},
year = {2009},
isbn = {9781605584973},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1629911.1630048},
doi = {10.1145/1629911.1630048},
abstract = {The availability of multicore processors across a wide range of computing platforms has created a strong demand for software frameworks that can harness these resources. This paper overviews the Cilk++ programming environment, which incorporates a compiler, a runtime system, and a race-detection tool. The Cilk++ runtime system guarantees to load-balance computations effectively. To cope with legacy codes containing global variables, Cilk++ provides a "hyperobject" library which allows races on nonlocal variables to be mitigated without lock contention or substantial code restructuring.},
booktitle = {Proceedings of the 46th Annual Design Automation Conference},
pages = {522–527},
numpages = {6},
keywords = {multithreading, dag model, speedup, race detection, parallel programming, hyperobject, work, reducer, parallelism, multicore programming, Amdahl's Law, span},
location = {San Francisco, California},
series = {DAC '09}
}

@article{BlumL1999,
author = {Blumofe, Robert D. and Leiserson, Charles E.},
title = {Scheduling Multithreaded Computations by Work Stealing},
year = {1999},
issue_date = {Sept. 1999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {5},
issn = {0004-5411},
url = {https://doi.org/10.1145/324133.324234},
doi = {10.1145/324133.324234},
abstract = {This paper studies the problem of efficiently schedulling fully strict (i.e., well-structured) multithreaded computations on parallel computers. A popular and practical method of scheduling this kind of dynamic MIMD-style computation is “work stealing,” in which processors needing work steal computational threads from other processors. In this paper, we give the first provably good work-stealing scheduler for multithreaded computations with dependencies.Specifically, our analysis shows that the expected time to execute a fully strict computation on P processors using our work-stealing scheduler is T1/P + O(T ∞ , where T1 is the minimum serial execution time of the multithreaded computation and (T ∞ is the minimum execution time with an infinite number of processors. Moreover, the space required by the execution is at most S1P, where S1 is the minimum serial space requirement. We also show that the expected total communication of the algorithm is at most O(PT ∞( 1 + nd)Smax), where Smax is the size of the largest activation record of any thread and nd is the maximum number of times that any thread synchronizes with its parent. This communication bound justifies the folk wisdom that work-stealing schedulers are more communication efficient than their work-sharing counterparts. All three of these bounds are existentially optimal to within a constant factor.},
journal = {J. ACM},
month = sep,
pages = {720–748},
numpages = {29},
keywords = {multiprocessor, thread scheduling, randomized algorithm, work stealing, multithreading, critical-path length}
}

@article{GHHIK2019,
author = {Grove, David and Hamouda, Sara S. and Herta, Benjamin and Iyengar, Arun and Kawachiya, Kiyokuni and Milthorpe, Josh and Saraswat, Vijay and Shinnar, Avraham and Takeuchi, Mikio and Tardieu, Olivier},
title = {Failure Recovery in Resilient X10},
year = {2019},
issue_date = {July 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {41},
number = {3},
issn = {0164-0925},
url = {https://doi.org/10.1145/3332372},
doi = {10.1145/3332372},
journal = {ACM Trans. Program. Lang. Syst.},
month = jul,
articleno = {Article 15},
numpages = {30},
keywords = {APGAS, X10}
}

@inproceedings{RobBK2016,
 author = {Robson, Michael P. and Buch, Ronak and Kale, Laxmikant V.},
 title = {Runtime Coordinated Heterogeneous Tasks in Charm++},
 booktitle = {Proceedings of the Second Internationsl Workshop on Extreme Scale Programming Models and Middleware},
 series = {ESPM2},
 year = {2016},
 isbn = {978-1-5090-3858-9},
 location = {Salt Lake City, Utah},
 pages = {40--43},
 numpages = {4},
 url = {https://doi.org/10.1109/ESPM2.2016.7},
 doi = {10.1109/ESPM2.2016.7},
 acmid = {3018821},
 publisher = {IEEE Press},
 address = {Piscataway, NJ, USA},
 keywords = {accelerator architectures, high performance computing, parallel programming, runtime},
}

@inproceedings{KaleK1993,
  author        = "{Kal\'{e}}, L.V. and Krishnan, S.",
  title         = "{CHARM++: A Portable Concurrent Object Oriented System  Based on C++}",
  editor        = "Paepcke, A.",
  fulleditor    = "Paepcke, Andreas",
  pages         = "91--108",
  Month         = "September",
  Year          = "1993",
  booktitle     = "{Proceedings of OOPSLA'93}",
  publisher     = "{ACM Press}",
}

@article{ThaTL2005,
author = {Thain, Douglas and Tannenbaum, Todd and Livny, Miron},
title = {Distributed computing in practice: the Condor experience},
journal = {Concurrency and Computation: Practice and Experience},
volume = {17},
number = {24},
pages = {323-356},
keywords = {Condor, Grid, history, community, planning, scheduling, split execution},
doi = {10.1002/cpe.938},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.938},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/cpe.938},
abstract = {Abstract Since 1984, the Condor project has enabled ordinary users to do extraordinary computing. Today, the project continues to explore the social and technical problems of cooperative computing on scales ranging from the desktop to the world-wide computational Grid. In this paper, we provide the history and philosophy of the Condor project and describe how it has interacted with other projects and evolved along with the field of distributed computing. We outline the core components of the Condor system and describe how the technology of computing must correspond to social structures. Throughout, we reflect on the lessons of experience and chart the course travelled by research ideas as they grow into production systems. Copyright Â© 2005 John Wiley \& Sons, Ltd.},
year = {2005}
}

@inproceedings{PerRL2007,
  title={A Flexible and Portable Programming Model for SMP and Multi-cores BSC-UPC COMPUTER SCIENCES PROGRAM},
  author={J. M. P{\'e}rez and R. M. Badia and J. Labarta},
  year={2007}
}

@inproceedings{LiHGW2019a,
author = {Lin, Chun-Xun and Huang, Tsung-Wei and Guo, Guannan and Wong, Martin D. F.},
title = {A Modern C++ Parallel Task Programming Library},
year = {2019},
isbn = {9781450368896},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3343031.3350537},
doi = {10.1145/3343031.3350537},
abstract = {In this paper we present Cpp-Taskflow, a C++ parallel programming library that enables users to quickly develop parallel applications using the task dependency graph model. Developers formulate their application as a task dependency graph and Cpp-Taskflow will manage the task execution and concurrency control.The task graph model is expressive and composable. It can express both regular and irregular parallel patterns, and developers can quickly compose large programs from small parallel modules. Cpp-Taskflow has an intuitive and unified API set. Users only need to learn the APIs to build and dispatch a task graph and no complex parallel programming concept is required. We have conducted experiments using both micro-benchmarks and real-world applications and Cpp-Taskflow outperforms state-of-the-art parallel programming libraries in both runtime and coding effort. Cpp-Taskflow is open-source and has been used in both industry and academic projects. From our users' feedback, we believe Cpp-Taskflow can benefit the industry and research community greatly through its ease-of-programming and inspire new research directions in multimedia system/software design.},
booktitle = {Proceedings of the 27th ACM International Conference on Multimedia},
pages = {2284–2287},
numpages = {4},
keywords = {task parallelism, task dependency graph, parallel programming},
location = {Nice, France},
series = {MM '19}
}

@INPROCEEDINGS{HuLGW2019,
 author={T. {Huang} and C. {Lin} and G. {Guo} and M. {Wong}},
booktitle={2019 IEEE International Parallel and Distributed Processing Symposium (IPDPS)},
title={Cpp-Taskflow: Fast Task-Based Parallel Programming Using Modern C++},
year={2019},
volume={},
number={},
pages={974-983},}

@INPROCEEDINGS{LiHGW2019b,
  author={C. {Lin} and T. {Huang} and G. {Guo} and M. D. F. {Wong}},
  booktitle={2019 IEEE High Performance Extreme Computing Conference (HPEC)},
  title={An Efficient and Composable Parallel Task Programming Library},
  year={2019},
  volume={},
  number={},
  pages={1-7},}

@TechReport{HPHSD2019,
  author =    "J. K. Holmen and B. Peterson and A. Humphrey and
              D. Sunderland and O. H. Diaz-Ibarra and J. N.
              Thornock and M. Berzins",
  title =     "Portably Improving Uintah's Readiness for Exascale
              Systems Through the Use of Kokkos",
  year =      "2019",
  institution = "SCI Institute",
  url =       "http://www.sci.utah.edu/publications/Hol2019a/UUSCI-2019-001.pdf",
}

@InProceedings{HumpB2019,
  author =    "A. Humphrey and M. Berzins",
  title =     "An Evaluation of An Asynchronous Task Based
              Dataflow Approach For Uintah",
  booktitle = "2019 IEEE 43rd Annual Computer Software and
              Applications Conference (COMPSAC)",
  volume =    "2",
  pages =     "652-657",
  year =      "2019",
  month =     "July",
  issn =      "0730-3157",
  url =       "http://www.sci.utah.edu/publications/Hum2019b/dfm19_humphrey_berzins.pdf",
}

@article{CarTS2014,
  title = "Kokkos: Enabling manycore performance portability through polymorphic memory access patterns",
  journal = "Journal of Parallel and Distributed Computing",
  volume = "74",
  number = "12",
  pages = "3202 - 3216",
  year = "2014",
  note = "Domain-Specific Languages and High-Level Frameworks for High-Performance Computing",
  issn = "0743-7315",
  doi = "https://doi.org/10.1016/j.jpdc.2014.07.003",
  url = "http://www.sciencedirect.com/science/article/pii/S0743731514001257",
  author = "H. Carter Edwards and Christian R. Trott and Daniel Sunderland"
}

@article{CartI2017,
title = {Kokkos' Task DAG Capabilities.},
author = {Edwards, Harold C. and Ibanez, Daniel Alejandro},
abstractNote = {This report documents the ASC/ATDM Kokkos deliverable "Production Portable Dynamic Task DAG Capability." This capability enables applications to create and execute a dynamic task DAG ; a collection of heterogeneous computational tasks with a directed acyclic graph (DAG) of "execute after" dependencies where tasks and their dependencies are dynamically created and destroyed as tasks execute. The Kokkos task scheduler executes the dynamic task DAG on the target execution resource; e.g. a multicore CPU, a manycore CPU such as Intel's Knights Landing (KNL), or an NVIDIA GPU. Several major technical challenges had to be addressed during development of Kokkos' Task DAG capability: (1) portability to a GPU with it's simplified hardware and micro- runtime, (2) thread-scalable memory allocation and deallocation from a bounded pool of memory, (3) thread-scalable scheduler for dynamic task DAG, (4) usability by applications.},
doi = {10.2172/1398234},
place = {United States},
year = {2017},
month = {9}
}

@ARTICLE{ACDHM2009,
  author={E. {Ayguade} and N. {Copty} and A. {Duran} and J. {Hoeflinger} and Y. {Lin} and F. {Massaioli} and X. {Teruel} and P. {Unnikrishnan} and G. {Zhang}},
  journal={IEEE Transactions on Parallel and Distributed Systems},
  title={The Design of OpenMP Tasks},
  year={2009},
  volume={20},
  number={3},
  pages={404-418},}

@inproceedings{YarkKD2011,
  title={QUARK Users' Guide: QUeueing And Runtime for Kernels},
  author={A. YarKhan and J. Kurzak and J. Dongarra},
  year={2011}
}

@Manual{Dask2016,
  title = {Dask: Library for dynamic task scheduling},
  author = {{Dask Development Team}},
  year = {2016},
  url = {https://dask.org},
}

@book{Reind2007,
author = {Reinders, James},
title = {Intel Threading Building Blocks},
year = {2007},
doi = {10.5555/1461409},
isbn = {9780596514808},
publisher = {O'Reilly and Associates, Inc.},
address = {USA},
edition = {First}
}

@article{Pheat2008,
author = {Pheatt, Chuck},
title = {Intel Threading Building Blocks},
year = {2008},
issue_date = {April 2008},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {23},
number = {4},
issn = {1937-4771},
doi = {10.5555/1352079.1352134},
month = apr,
pages = {298},
numpages = {1}
}

@Article{SahaB2019,
  author =    "D. Sahasrabudhe and M. Berzins and J. Schmidt",
  title =     "Node failure resiliency for Uintah without
              checkpointing",
  journal =   "Concurrency and Computation: Practice and
              Experience",
  pages =     "e5340",
  year =      "2019",
  url =       "http://www.sci.utah.edu/publications/Sah2019a/00_Uintah_Resiliency.pdf",
}

@InProceedings{PetiW1992,
author="Petiton, Serge
and Weill-Duflos, Christine",
editor="Boug{\'e}, Luc
and Cosnard, Michel
and Robert, Yves
and Trystram, Denis",
title="Massively parallel preconditioners for the sparse conjugate gradient method",
booktitle="Parallel Processing: CONPAR 92---VAPP V",
year="1992",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="373--378",
abstract="We study the conjugate gradient method to solve large sparse linear systems with two ways of preconditioning: the polynomial and the ILU preconditionings. A parallel version is evaluated on the Connection Machine 2 (CM-2) with large sparse matrices. Results show that we must find a tradeoff between high performance (in terms of Mflops) and fast convergence. We first conclude that to find efficient methods on massively parallel computers, especially when irregular structures were used, parallelising usual algorithms is not always the most efficient way. Then, we introduce the new massively parallel hybrid polynomial-ILUTmp (l, $\epsilon$, d) preconditioning for distributed memory machines using a data parallel programming model.",
isbn="978-3-540-47306-0"
}

@article{GeleC1992,
author = {Gelernter, David and Carriero, Nicholas},
title = {Coordination Languages and Their Significance},
year = {1992},
issue_date = {Feb. 1992},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {35},
number = {2},
issn = {0001-0782},
url = {https://doi.org/10.1145/129630.129635},
doi = {10.1145/129630.129635},
journal = {Commun. ACM},
month = feb,
pages = {97–107},
numpages = {11},
keywords = {Linda, coordination languages}
}

@article{CaGMS1994,
title = "The Linda alternative to message-passing systems",
journal = "Parallel Computing",
volume = "20",
number = "4",
pages = "633 - 655",
year = "1994",
note = "Message Passing Interfaces",
issn = "0167-8191",
doi = "https://doi.org/10.1016/0167-8191(94)90032-9",
url = "http://www.sciencedirect.com/science/article/pii/0167819194900329",
author = "Nicholas J Carriero and David Gelernter and Timothy G Mattson and Andrew H Sherman",
keywords = "Message passing, LINDA, Virtual shared memory, Evaluation, Parallel programming paradigm",
abstract = "The use of distributed data structures in a logically-shared memory is a natural, readily-understood approach to parallel programming. The principal argument against such an approach for portable software has always been that efficient implementations could not scale to massively-parallel, distributed memory machines. Now, however, there is growing evidence that it is possible to develop efficient and portable implementations of virtual shared memory models on scalable architectures. In this paper we discuss one particular example: Linda. After presenting an introduction to the Linda model, we focus on the expressiveness of the model, on techniques required to build efficient implementations, and on observed performance both on workstation networks and distributed-memory parallel machines. Finally, we conclude by briefly discussing the range of applications developed with Linda and Linda's suitability for the sorts of heterogeneous, dynamically-changing computational environments that are of growing significance."
}

@techreport{ButRL1992,
  title={User's guide to the p4 parallel programming system},
  author={Butler, Ralph and Lusk, Ewing},
  year={1992},
  institution={Technical Report ANL-92/17, Argonne National Laboratory}
}

@incollection{PGMLB2019,
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {8024--8035},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}
}

@inproceedings{DeanG2004,
author = {Dean, Jeffrey and Ghemawat, Sanjay},
title = {MapReduce: Simplified Data Processing on Large Clusters},
year = {2004},
publisher = {USENIX Association},
address = {USA},
abstract = {MapReduce is a programming model and an associated implementation for processing and generating large data sets. Users specify a map function that processes a key/value pair to generate a set of intermediate key/value pairs, and a reduce function that merges all intermediate values associated with the same intermediate key. Many real world tasks are expressible in this model, as shown in the paper.Programs written in this functional style are automatically parallelized and executed on a large cluster of commodity machines. The run-time system takes care of the details of partitioning the input data, scheduling the program's execution across a set of machines, handling machine failures, and managing the required inter-machine communication. This allows programmers without any experience with parallel and distributed systems to easily utilize the resources of a large distributed system.Our implementation of MapReduce runs on a large cluster of commodity machines and is highly scalable: a typical MapReduce computation processes many terabytes of data on thousands of machines. Programmers find the system easy to use: hundreds of MapReduce programs have been implemented and upwards of one thousand MapReduce jobs are executed on Google's clusters every day.},
booktitle = {Proceedings of the 6th Conference on Symposium on Operating Systems Design and Implementation - Volume 6},
pages = {10},
numpages = {1},
location = {San Francisco, CA},
series = {OSDI'04}
}


@techreport{EiESS1977,
title = "The Yale Sparse Matrix Package",
year = "1977",
author = "Stanley C. Eisenstat and Howard C. Elman and Martin H. Schultz and Andrew H. Sherman",
institution = " Office of Naval Research under contract N00014-82-K-0184 and National Science Foundation under grant MCS-81-04874"
}

@article{ToMRG2012,
author = {Yoshida, Toshio and Hondo, Mikio and Kan, Ryuji and Sugizaki, Go},
year = {2012},
month = {07},
pages = {274-279},
title = {SPARC64 VIIIfx: CPU for the K computer},
volume = {48},
journal = {Fujitsu scientific and technical journal}
}

@conference{EPPSA2016,
	title = {Systemwide Power Management with Argo},
	booktitle = {Parallel and Distributed Processing Symposium Workshops},
	year = {2016},
	publisher = {IEEE},
	organization = {IEEE},
	doi = {10.1109/IPDPSW.2016.81},
	author = {D. Ellsworth and T. Patki and S. Perarnau and S. Seo and Amer, Abdelhalim and J. A. Zounmevo and R. Gupta and K. Yoshii and H. Hoffman and Allen Malony and M. Schulz and Peter H. Beckman}
}

@phdthesis{Wu2019,
    title    = {Contribution to the Emergence of New Intelligent Parallel and Distributed Methods Using a Multi-level Programming Paradigm for Extreme Computing},
    school   = {University of Lille},
    author   = {Wu, Xinzhe},
    year     = {2019}
}

@misc{PetGC2020,
place={Seattle},
title={A Taxonomy of Distributed and Parallel Languages for High Performance Tasks-Based Multilevel Computing},
journal={SIAM 2020 Conference on Parallel Processing for Scientific Computing},
author={Petiton, Serge G. and Gurhem, Jérôme and Calandra, Henri},
year={2020},
month={Feb}}