\chapter{Introduction}

\section{Motivations}
Previously, the computing power of processors was mainly increasing with the frequency of the processors which cannot be increased easily anymore due the heat generation and the energy consumption increasing alongside.
Therefore, a major change in the architecture occurred in order to still increase the performances of the new supercomputers : more processors with tens of cores were introduced in supercomputers.
Moreover, graphic processing unit (GPU) also made their appearance in supercomputer nodes due to their high performances considering their low energy consumption compared to regular processes.
This leads to an increasing number of different architectures from which the users have to obtain performances.

Furthermore, in the recent massively parallel architectures, the users have to take advantage of multiple nodes constituted of several multi-core processors connected by network to achieve performance, which is done by implementing parallel applications.
Moreover, taking advantage of multiple nodes containing several multi-core processors involves the use of the network to send data from one node to another since the memory is local to the nodes.
Besides, new processors with a network on chip are also appearing on supercomputers like Fugaku A64FX CPUs and Sunway TaihuLight SW26010.
In these processors, the cores are not sharing the same memory.
Instead, there is a network that can be used to send data from one subset of core to the others.
These processors have hierarchical memory and network in which distributed memory is introduced at several level.
There is distributed memory at the level of supercomputer nodes and at the level of the groups of cores in the processor.

Nowadays, parallel and distributed applications are based on MPI+X where MPI is the Message Passing Interface \cite{MPIForum}, that is used to send the data between the nodes, and X is a parallel programming model that is used to take advantage of the computing resources of the nodes.
Usually, X may be OpenMP \cite{DaguM1998}, that takes advantage of shared memory and multi-threading to achieve performance on CPU and GPU and/or CUDA \cite{Shane2012}, that addresses parallelism on NVidia GPUs.
Applications can also implemented with pure MPI where MPI is used to spawn multiple processes on each node.
With the increase of available architectures (a combination of different generation of CPU and GPU), the portability of highly optimized applications for a given architecture is not assured on another architecture.
If the architecture is too different, it may also be possible that the application cannot be installed due to missing libraries dependent on a given architecture.

However, MPI may not be a solution efficient enough on exascale machines, especially in terms of fault tolerance and check-pointing \cite{SWAAB2014}.
Task-based approach can help in managing fault tolerance and check-pointing since the tasks could be restarted on another location and data from tasks saved at any moment.
Task based programming models can implement fault tolerance by restarting the failed tasks on other computing resources and even stop executing tasks on processors with high fault rate.
Check-pointing could be implemented by storing the state of the output of the task in a way that allow to restart the application at the last check-point and reconstruct the lost data.
Moreover, task based programming models can also be used to avoid collective communications like reductions, broadcast or gather by transforming them into multiple operations on tasks.
Then, these operations can be scheduled by the programming scheduler to place the data and computations in a way that optimize and reduce the data communications.
Therefore, with the merging of parallel and distributed programming, graph of tasks and efficient scheduler are a very interesting way to improve performances while reducing communications.
Schedulers that can optimize data migrations and task execution while keeping good performances are necessary.

While MPI focus on exchanging data between processes, other programming models may be efficient to parallelize applications with good scalability without being held back by global synchronizations.
For instance, Partitioned Global Address Space Languages (PGAS) programming models, that let the users see the distributed memory as a global memory address space that is partitioned across each processing element \cite{CDMCE2005}, are an alternative to MPI + X.
Task-based programming models, which allow to define fine-grain tasks (computations) on a specific set of data (input and output), are also an alternative to MPI.
Runtime systems which can optimize execution are another one.
Moreover, task-based programming models (first level of parallelism) combined with coarse-grain tasks implemented in a PGAS language (second level of parallelism) can also be one of them.
Usually, fine-grain tasks use one process (eventually multi-threaded) whereas coarse-grain tasks perform on several processes (eventually with distributed memory).

\section{Objectives and Contributions}

As programming models are evolving rapidly, it is important to have a clear view of the main capabilities of the current programming models in order to use the most suitable programming model to the targeted architectures and the implemented application.
Some have a high level of abstraction, others, more pragmatic, are based on adding pragmas to existing software.
The existence of several levels of parallelism also generates programming paradigms mixing several approaches.
Moreover, the development of realistic scientific applications in this context is very complex and cannot be considered for each experiment related to this research.
The main objective of this thesis is to study what must be task-based programming for scientific applications and to propose a specification of such distributed and parallel programming, by experimenting for several simplified representations of important scientific applications for TOTAL.
The optimization of data movements is studied and scheduling strategies are proposed and evaluated.
During the dissertation, several programming languages and paradigms are studied.
Software is developed using these programming models for each simplified applications.
As a result of this research, a methodology for parallel task programming is proposed, optimizing data movements, in general, and for targeted scientific applications, in particular.
A taxonomy of these languages and a strategy of evolution between the current codes and those respecting this methodology is introduced in the dissertation.

The first contribution of this dissertation is an in-depth analyze of several task based parallel and distributed programming models.
We compare and evaluate PaRSEC \cite{BBDHL2011}, Legion \cite{BaTSA2012}, Regent \cite{SLTBA2015}, TensorFlow \cite{AABBC2016}, HPX \cite{KHASF2014}, YML+XMP \cite{DelaP2004}, Pegasus \cite{DSSBG2005} and Swift \cite{ZHCFL2007}.
TensorFlow is not a general purpose programming model since it mainly focuses on linear algebra and machine learning.
However, it proposes tasks definition interfaces similar to the other task based programming models.
PaRSEC, Legion, Regent and HPX are fine grained task based programming models where the tasks run on only one computing unit (a thread or a process) whereas YML+XMP, Pegasus and Swift are large grain task based programming model where the tasks can run on distributed resources (from one process to multiple processes on different nodes of a supercomputer).

These task based programming models are used to implement three applications which are the second contribution of this dissertation.
The first application is a block based dense linear solver based on three algorithms : the block LU factorization, the block Gaussian elimination and the block Gauss-Jordan elimination.
This application has been implemented in XMP, MPI, YML+XMP, Regent, TensorFlow, Pegasus and HPX.
A block based task sparse matrix vector product has been implemented in MPI, HPX and YML+XMP.
It can perform the sparse matrix vector product with the COO, CSR and ELLPACK sparse matrix storage format as well as the dense format.
Moreover, this application also supports multiple data distribution.
Indeed, the matrix can distributed by block of rows, by block of columns and a rectangular block of rows and columns.
The last considered application is a simplified version of the Kirchhoff seismic pre-stack depth migration which is implemented with MPI and HPX.

Finally, the last contribution of this dissertation is a taxonomy of the task based programming models where the features are extracted from the comparisons and analyzes of the task based programming models.
This taxonomy summarizes the expertise gained on the task programming models encountered during the work on this dissertation.
We analyze the introduced algorithms and task based programming models features in order to highlight the most suited features to use in implementing the applications.
We conclude on which category of algorithms can be efficiently implemented into an application relying on parallel and distributed task based programming models.
% TODO ; update when the chapters will be writen (taxo and after)

\section{Outline}
This dissertation is organized as follows. In Chapter \ref{chap:hpc}, we present the start-of-the-art of the task based high performance computing including programming models currently used in order to achieve performances and a presentation of the recent task based programming models.
Finally, we discuss the challenges the HPC community is facing for the exascale supercomputers.

In Chapter \ref{chap:methods}, the algorithms of the methods implemented as a benchmark for the task based programming models are covered.
The three considered methods are a block based dense linear solver, the block based task sparse matrix vector product and the Kirchhoff seismic pre-stack depth migration.

A selection of task based programming models are introduced with more detail in Chapter \ref{chap:languages}.
We outline the main features of each programming models studied and how to use them to define task, the dependencies between them, how to register the data used in the tasks and how to execute the tasks to perform the intended computations.

Afterwards, we detail the implementation of the block LU factorization, the block Gaussian elimination and the block Gauss-Jordan elimination.
In Chapter \ref{chap:exp_dense}, we also present the experiments performed on the K computer and the Poincare cluster as well as the results obtained with our applications compared to our MPI scalar implementation as well as ScaLAPACK.
We also perform experiments with the block LU factorization on the Poincare cluster in which we compare our implementations of the block LU.
We implemented it in Regent, HPX, YML+XM, PaRSEC, MPI and XMP.

In Chapter \ref{chap:exp_sparse}, we introduce the data distribution we use to split the sparse matrices on the multiples nodes available during the run of the application.
We present how we distribute the matrix by block of rows, by block of columns and a rectangular block of rows and columns.
Then, we explain how the tasks are defined depending of the data distribution and the different sparse matrix storage we use.
Finally, we present the numerical results we obtained on the supercomputers on which we ran experiments.

Furthermore, the algorithm of the task based Kirchhoff seismic pre-stack depth migration are introduced in Chapter \ref{chap:exp_km}.
Its implementation is also detailed in this chapter as well as the numerical experiments performed.

The taxonomy with the features we extracted from the analyze of the programming models in the previous chapters is presented in Chapter \ref{chap:taxonomy}.
We highlight these features in the other programming models and find how these features are implemented in the considered programming models.
% TODO : update depending on what will be written in the actual chapter \ref{chap:taxonomy}

In Chapter \ref{chap:properties+extension}, the properties of the task based programming models are discussed and a proposition of what kind of properties task based programming models should have is made.
% TODO : update depending on what will be written in the actual chapter \ref{chap:properties+extension}

To conclude, the key results obtained in this thesis are summarized in Chapter \ref{chap:ccl} and the concluding remarks are presented.
Finally, we suggest some possible paths to future research.
